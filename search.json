[{"path":"index.html","id":"sykdomspulsen-core-in-depth","chapter":"Sykdomspulsen Core in Depth","heading":"Sykdomspulsen Core in Depth","text":"Sykdomspulsen Core free open-source backbone Sykdomspulsen.Sykdomspulsen Core standalone R package, means easy teams build surveillance infrastructure based Sykdomspulsen Core.","code":""},{"path":"authors.html","id":"authors","chapter":"Authors","heading":"Authors","text":"Written Richard Aubrey White Aurora Christine Hofman.","code":""},{"path":"db-schemas.html","id":"db-schemas","chapter":"1 DB Schemas","heading":"1 DB Schemas","text":"","code":""},{"path":"db-schemas.html","id":"introduction","chapter":"1 DB Schemas","heading":"1.1 Introduction","text":"database schema way representing database constructed. short, can think database tables.","code":""},{"path":"db-schemas.html","id":"database-servers","chapter":"1 DB Schemas","heading":"1.2 Database servers","text":"Normally, implementation Sykdomspulsen Core two database servers run parallel systems. One database server auto interactive.run code RStudio Workbench Airflow interactive, automatically connected interactive database server. run code Airflow auto, automatically connected auto database server. something implementation solve.","code":""},{"path":"db-schemas.html","id":"access-level-anonrestrredirect","chapter":"1 DB Schemas","heading":"1.3 Access level (anon/restr/redirect)","text":"Within database server, multiple databases different access levels censoring requirements.Censoring performed via db schema.","code":""},{"path":"db-schemas.html","id":"anon","chapter":"1 DB Schemas","heading":"1.3.1 anon","text":"“anonymous” database contains data anonymous. team members access database.","code":""},{"path":"db-schemas.html","id":"restr","chapter":"1 DB Schemas","heading":"1.3.2 restr","text":"“restricted” database contains data :Indirectly identifiableAnonymousOnly restricted number team members access database.","code":""},{"path":"db-schemas.html","id":"redirect","chapter":"1 DB Schemas","heading":"1.3.3 redirect","text":"technically database, however, treated one.person creates db schema exists anonymous restricted databases, Sykdomspulsen Core automatically detect highest level access connect database working redirect schemas.","code":""},{"path":"db-schemas.html","id":"creating-your-own","chapter":"1 DB Schemas","heading":"1.4 Creating your own","text":"Sykdomspulsen Core requires lot boilerplate code. strongly recommended use RStudio Addins menu help quickly insert code templates.generate three database schemas:restr_example (specified via name_access)anon_example (specified via name_access)redirect_example (automatically created restr anon used)schema main parts.","code":"\nsc::add_schema_v8(\n  name_access = c(\"restr\", \"anon\"),\n  name_grouping = \"example\",\n  name_variant = NULL,\n  db_configs = sc::config$db_configs,\n  field_types =  c(\n    \"granularity_time\" = \"TEXT\",\n    \"granularity_geo\" = \"TEXT\",\n    \"country_iso3\" = \"TEXT\",\n    \"location_code\" = \"TEXT\",\n    \"border\" = \"INTEGER\",\n    \"age\" = \"TEXT\",\n    \"sex\" = \"TEXT\",\n    \n    \"date\" = \"DATE\",\n    \n    \"isoyear\" = \"INTEGER\",\n    \"isoweek\" = \"INTEGER\",\n    \"isoyearweek\" = \"TEXT\",\n    \"season\" = \"TEXT\",\n    \"seasonweek\" = \"DOUBLE\",\n    \n    \"calyear\" = \"INTEGER\",\n    \"calmonth\" = \"INTEGER\",\n    \"calyearmonth\" = \"TEXT\",\n\n    \"value_n\" = \"INTEGER\"\n  ),\n  keys = c(\n    \"granularity_time\",\n    \"location_code\",\n    \"date\",\n    \"age\",\n    \"sex\"\n  ),\n  censors = list(\n    restr = list(\n      value_n = sc::censor_function_factory_nothing(\"value_n\")\n    ),\n    anon = list(\n      value_n = sc::censor_function_factory_values_0_4(\"value_n\")\n    )\n  ),\n  validator_field_types = sc::validator_field_types_sykdomspulsen,\n  validator_field_contents = sc::validator_field_contents_sykdomspulsen,\n  info = \"This db table is used for...\"\n)"},{"path":"db-schemas.html","id":"naming","chapter":"1 DB Schemas","heading":"1.4.1 Naming","text":"db schemas tables given names: name_access_name_grouping_name_variantIn example, three db schemas:restr_example (accessible sc::config$schemas$restr_example)anon_example (accessible sc::config$schemas$anon_example)redirect_example (accessible sc::config$schemas$redirect_example)Corresponding two db tables:restr_exampleanon_example","code":""},{"path":"db-schemas.html","id":"name_access","chapter":"1 DB Schemas","heading":"1.4.1.1 name_access","text":"Either restr anon","code":""},{"path":"db-schemas.html","id":"name_grouping","chapter":"1 DB Schemas","heading":"1.4.1.2 name_grouping","text":"descriptive name","code":""},{"path":"db-schemas.html","id":"name_variant","chapter":"1 DB Schemas","heading":"1.4.1.3 name_variant","text":"descriptive name","code":""},{"path":"db-schemas.html","id":"db_configs","chapter":"1 DB Schemas","heading":"1.4.2 db_configs","text":"list contains information database:","code":"\nnames(sc::config$db_configs)\n## [1] \"restr\"         \"anon\"          \"specific_daar\" \"config\""},{"path":"db-schemas.html","id":"db_field_types","chapter":"1 DB Schemas","heading":"1.4.3 db_field_types","text":"vector containing names variable types columns database table.vast majority cases, first 16 columns standardized always .Permitted variable types :TEXTDOUBLEINTEGERBOOLEANDATEDATETIME","code":""},{"path":"db-schemas.html","id":"keys","chapter":"1 DB Schemas","heading":"1.4.4 keys","text":"columns form primary key database table (.e. identify unique rows).","code":""},{"path":"db-schemas.html","id":"censors","chapter":"1 DB Schemas","heading":"1.4.5 censors","text":"","code":""},{"path":"db-schemas.html","id":"validator_field_types","chapter":"1 DB Schemas","heading":"1.4.6 validator_field_types","text":"validator useful ensuring database table names consistent predetermined rules. example, Sykdomspulsen decided always want first 16 columns :granularity_timegranularity_geocountry_iso3location_codeborderagesexdateisoyearisoweekisoyearweekseasonseasonweekcalyearcalmonthcalyearmonthWhile developing new code found difficult force developers remember include 16 columns correct order. validator sc::validator_field_types_sykdomspulsen ensures first 16 columns expected, otherwise developer able run code.validator_field_contents validator ensures contents data correct. experienced issues granularity_time sometimes containing value week sometimes containing value weekly. maintain consistency data, validator sc::validator_field_contents_sykdomspulsen throw error observes non-accepted values certain variables.","code":""},{"path":"db-schemas.html","id":"loading-data-into-a-db-schema","chapter":"1 DB Schemas","heading":"1.5 Loading data into a db schema","text":"Checklist:Remember “keys” (defined sc::add_schema_v8) defines uniquely identifying rows data allowed db tableUse sc::fill_in_missing_v8(d)Choose method loading data (upsert/insert/drop_all_rows_and_then_upsert_data)check see schemas available:create fictional dataset work .","code":"\nstringr::str_subset(names(sc::config$schemas), \"_example$\")\n## [1] \"restr_example\"    \"anon_example\"     \"redirect_example\"\noptions(width = 150)\n# fictional dataset\nd <- data.table(\n  granularity_time = \"day\",\n  granularity_geo = \"nation\",\n  country_iso3 = \"nor\",\n  location_code = \"norge\",\n  border = 2020,\n  age = \"total\",\n  sex = \"total\",\n  \n  date = c(as.Date(\"1990-01-07\"),as.Date(\"1990-01-08\")),\n  \n  isoyear = 1990,\n  isoweek = 1,\n  isoyearweek = \"1990-01\",\n  season = \"1990/1991\",\n  seasonweek = 24,\n  \n  calyear = NA,\n  calmonth = NA,\n  calyearmonth = NA,\n  \n  value_n = c(3,6)\n)\n\n# display the raw data\nd[]\n##    granularity_time granularity_geo country_iso3 location_code border   age   sex       date isoyear isoweek isoyearweek    season seasonweek calyear\n## 1:              day          nation          nor         norge   2020 total total 1990-01-07    1990       1     1990-01 1990/1991         24      NA\n## 2:              day          nation          nor         norge   2020 total total 1990-01-08    1990       1     1990-01 1990/1991         24      NA\n##    calmonth calyearmonth value_n\n## 1:       NA           NA       3\n## 2:       NA           NA       6\n\n# always fill in missing data!\nsc::fill_in_missing_v8(d)\n\n# we have four options to get the data into the db table\n# remember that \"keys\" defines the uniquely identifying rows of data that are allowed in the db table!\n# - upsert means \"update if data exists, otherwise append\"\n# - insert means \"append\" (data cannot already exist)\n\nsc::config$schemas$redirect_example$upsert_data(d)\n## Creating table restr_example\n## Creating table anon_example\n#sc::config$schemas$redirect_example$insert_data(d)\n#sc::config$schemas$redirect_example$drop_all_rows_and_then_upsert_data(d)\n#sc::config$schemas$redirect_example$drop_all_rows_and_then_insert_data(d)"},{"path":"db-schemas.html","id":"accessing-the-data-in-a-db-schema","chapter":"1 DB Schemas","heading":"1.6 Accessing the data in a db schema","text":"Checklist:sc::mandatory_db_filterdplyr::selectWe extract data db schemas using dplyr dbplyr backend.can observe effects censoring defined sc::add_schema_v8","code":"\noptions(width = 150)\nsc::config$schemas$redirect_example$tbl() %>%\n  sc::mandatory_db_filter(\n    granularity_time = \"day\",\n    granularity_time_not = NULL,\n    granularity_geo = NULL,\n    granularity_geo_not = NULL,\n    country_iso3 = NULL,\n    location_code = \"norge\",\n    age = \"total\",\n    age_not = NULL,\n    sex = \"total\",\n    sex_not = NULL\n  ) %>%\n  dplyr::select(\n    granularity_time,\n    location_code,\n    date,\n    value_n,\n    value_n_censored\n  ) %>%\n  dplyr::collect() %>%\n  as.data.table() %>%\n  print()\n##    granularity_time location_code       date value_n value_n_censored\n## 1:              day         norge 1990-01-07       3            FALSE\n## 2:              day         norge 1990-01-08       6            FALSE\noptions(width = 150)\nsc::config$schemas$restr_example$tbl() %>%\n  sc::mandatory_db_filter(\n    granularity_time = \"day\",\n    granularity_time_not = NULL,\n    granularity_geo = NULL,\n    granularity_geo_not = NULL,\n    country_iso3 = NULL,\n    location_code = \"norge\",\n    age = \"total\",\n    age_not = NULL,\n    sex = \"total\",\n    sex_not = NULL\n  ) %>%\n  dplyr::select(\n    granularity_time,\n    location_code,\n    date,\n    value_n,\n    value_n_censored\n  ) %>%\n  dplyr::collect() %>%\n  as.data.table() %>%\n  print()\n##    granularity_time location_code       date value_n value_n_censored\n## 1:              day         norge 1990-01-07       3            FALSE\n## 2:              day         norge 1990-01-08       6            FALSE\n\nsc::config$schemas$anon_example$tbl() %>%\n  sc::mandatory_db_filter(\n    granularity_time = \"day\",\n    granularity_time_not = NULL,\n    granularity_geo = NULL,\n    granularity_geo_not = NULL,\n    country_iso3 = NULL,\n    location_code = \"norge\",\n    age = \"total\",\n    age_not = NULL,\n    sex = \"total\",\n    sex_not = NULL\n  ) %>%\n  dplyr::select(\n    granularity_time,\n    location_code,\n    date,\n    value_n,\n    value_n_censored\n  ) %>%\n  dplyr::collect() %>%\n  as.data.table() %>%\n  print()\n##    granularity_time location_code       date value_n value_n_censored\n## 1:              day         norge 1990-01-07       0             TRUE\n## 2:              day         norge 1990-01-08       6            FALSE"},{"path":"db-schemas.html","id":"accessing-the-data-in-ad-hoc-analyses","chapter":"1 DB Schemas","heading":"1.7 Accessing the data in ad-hoc analyses","text":"ad-hoc analyses, may access database tables via helper function sc::tblIT STRICTLY FORBIDDEN USE INSIDE SYKDOMSPULSEN TASKS!!!sc::tbl:SAFE use parallel programmingbypasses input/output control mechanisms apply sc::task_from_config_v8","code":"\noptions(width = 150)\nsc::tbl(\"restr_example\") %>%\n  sc::mandatory_db_filter(\n    granularity_time = \"day\",\n    granularity_time_not = NULL,\n    granularity_geo = NULL,\n    granularity_geo_not = NULL,\n    country_iso3 = NULL,\n    location_code = \"norge\",\n    age = \"total\",\n    age_not = NULL,\n    sex = \"total\",\n    sex_not = NULL\n  ) %>%\n  dplyr::select(\n    granularity_time,\n    location_code,\n    date,\n    value_n,\n    value_n_censored\n  ) %>%\n  dplyr::collect() %>% \n  as.data.table() %>% \n  print()\n##    granularity_time location_code       date value_n value_n_censored\n## 1:              day         norge 1990-01-07       3            FALSE\n## 2:              day         norge 1990-01-08       6            FALSE"},{"path":"db-schemas.html","id":"exploring-data-in-schemas","chapter":"1 DB Schemas","heading":"1.8 Exploring data in schemas","text":"DB Schemas obviously contain lot data. can overwhelming try understand inside schema.","code":"\noptions(width = 150)\n\n# Get the first few lines of the schema (use $tbl())\nsc::config$schemas$restr_example$tbl()\n## # Source:   table<restr_example> [?? x 18]\n## # Database: Microsoft SQL Server 12.00.6433[FHI\\RIWH@OFY-GN-SQL01/sykdomspulsen_interactive_restr]\n##   granularity_time granularity_geo country_iso3 location_code border age   sex   date       isoyear isoweek isoyearweek season    seasonweek calyear\n##   <chr>            <chr>           <chr>        <chr>          <int> <chr> <chr> <date>       <int>   <int> <chr>       <chr>          <dbl>   <int>\n## 1 day              nation          nor          norge           2020 total total 1990-01-07    1990       1 1990-01     1990/1991         24      NA\n## 2 day              nation          nor          norge           2020 total total 1990-01-08    1990       1 1990-01     1990/1991         24      NA\n## # … with 4 more variables: calmonth <int>, calyearmonth <chr>, value_n <int>, value_n_censored <lgl>\n\n# Get a summary of the schema (referencing the schema directly)\nsc::config$schemas$restr_example\n## [sykdomspulsen_interactive_restr].[dbo].[restr_example]   (connected)\n## \n## granularity_time (TEXT):\n##  - day (n = 2)\n## granularity_geo (TEXT):\n##  - nation (n = 2)\n## country_iso3 (TEXT):\n##  - nor (n = 2)\n## location_code (TEXT)\n## border (INTEGER):\n##  - 2020 (n = 2)\n## age (TEXT):\n##  - total (n = 2)\n## sex (TEXT):\n##  - total (n = 2)\n## date (DATE)\n## isoyear (INTEGER):\n##  - 1990 (n = 2)\n## isoweek (INTEGER)\n## isoyearweek (TEXT)\n## season (TEXT):\n##  - 1990/1991 (n = 2)\n## seasonweek (DOUBLE)\n## calyear (INTEGER)\n## calmonth (INTEGER)\n## calyearmonth (TEXT)\n## value_n (INTEGER)\n## value_n_censored (BOOLEAN)\n\n# Get a summary of a variable inside the schema via 'hashing the data structure'\nsc::config$schemas$restr_example %>%\n  spltidy::hash_data_structure(\"value_n\") %>%\n  plot()\n# This can also be done directly on a dbplyr table\nsc::tbl(\"restr_example\") %>%\n  spltidy::hash_data_structure(\"value_n\") %>%\n  plot()"},{"path":"tasks.html","id":"tasks","chapter":"2 Tasks","heading":"2 Tasks","text":"","code":""},{"path":"tasks.html","id":"introduction-1","chapter":"2 Tasks","heading":"2.1 Introduction","text":"task basic operational unit Sykdomspulsen Core. based plnr.short, can think Sykdomspulsen Core task multiple plnr plans plus Sykdomspulsen Core db schemas.","code":""},{"path":"tasks.html","id":"definitions","chapter":"2 Tasks","heading":"2.2 Definitions","text":"\n1 argset\n\n1 function takes two () arguments:\n\ndata (named list)\n\n\nargset (named list)\n\n\n… (optional arguments)\n\n\ndata (named list)\n\nargset (named list)\n\n… (optional arguments)\n\nargset (named list)\n\nschema (named list)\n\ndata (named list, returned data_selector_fn)\n\nargset (named list)\n\nschema (named list)\n\n1 argset\n\n1 action_fn\n\n1 data-pull (using data_selector_fn)\n\n1 list sc analyses\n\n1 list plans\n","code":""},{"path":"tasks.html","id":"general-tasks","chapter":"2 Tasks","heading":"2.3 General tasks","text":"\nFigure 2.1: general task showing many options task.\nFigure 2.1 shows us full potential task.Data can read sources, within plan data extracted data_selector_fn (.e. “one data-pull”). data provided analysis, run action_fn :provided dataThe provided argsetThe provided schemasThe action_fn can :Write data/results db schemasSend emailsExport graphs, excel files, reports, physical filesTypically subset done single task.","code":""},{"path":"tasks.html","id":"plan-heavy-or-analysis-heavy-tasks","chapter":"2 Tasks","heading":"2.3.1 Plan-heavy or analysis-heavy tasks?","text":"plan-heavy task one many plans analyses per plan.analysis-heavy task one plans many analyses per plan.general, data-pull slow wastes time. means preferable reduce number data-pulls performed data-pull extract larger quantities data. analysis can subset data required (identifed via argsets). .e. possible, analysis-heavy task preferable faster (cost needing RAM).Obviously, plan’s data-pull larger, use RAM. need conserve RAM, use plan-heavy approach.Figure 2.1 shows 2 location based analyses, reality 356 municipalities Norway 2021. figure 2.1 2 plans (1 2021 data, 1 2020 data) 356 analyses plan (1 location_code) taking analysis-heavy approach.","code":""},{"path":"tasks.html","id":"putting-it-together","chapter":"2 Tasks","heading":"2.4 Putting it together","text":"\nFigure 2.2: typical file setup implementation Sykdomspulsen Core. \\(plan_argset_fn\\) rarely used, therefore shown blacked tasks.\nFigure 2.2 shows typical implementation Sykdomspulsen Core.config_db.r contains Sykdomspulsen Core db schemas definitions. .e. long list sc::add_schema_v8 commands.config_tasks.r contains task definitions. .e. long list sc::add_task_from_config_v8 commands.one file task contains action_fn, data_selector_fn functions relevant task hand.","code":""},{"path":"tasks.html","id":"weather-example","chapter":"2 Tasks","heading":"2.5 Weather example","text":"now go example person design implement tasks relating weather","code":""},{"path":"tasks.html","id":"db-schema","chapter":"2 Tasks","heading":"2.5.1 db schema","text":"documented detail , create db schema fits needs (recording weather data).","code":"\nsc::add_schema_v8(\n  name_access = c(\"anon\"),\n  name_grouping = \"example_weather\",\n  name_variant = NULL,\n  db_configs = sc::config$db_configs,\n  field_types =  c(\n    \"granularity_time\" = \"TEXT\",\n    \"granularity_geo\" = \"TEXT\",\n    \"country_iso3\" = \"TEXT\",\n    \"location_code\" = \"TEXT\",\n    \"border\" = \"INTEGER\",\n    \"age\" = \"TEXT\",\n    \"sex\" = \"TEXT\",\n    \n    \"date\" = \"DATE\",\n    \n    \"isoyear\" = \"INTEGER\",\n    \"isoweek\" = \"INTEGER\",\n    \"isoyearweek\" = \"TEXT\",\n    \"season\" = \"TEXT\",\n    \"seasonweek\" = \"DOUBLE\",\n    \n    \"calyear\" = \"INTEGER\",\n    \"calmonth\" = \"INTEGER\",\n    \"calyearmonth\" = \"TEXT\",\n\n    \"tg\" = \"DOUBLE\",\n    \"tx\" = \"DOUBLE\",\n    \"tn\" = \"DOUBLE\",\n    \"rr\" = \"DOUBLE\"\n  ),\n  keys = c(\n    \"granularity_time\",\n    \"location_code\",\n    \"date\",\n    \"age\",\n    \"sex\"\n  ),\n  censors = list(\n    anon = list(\n      \n    )\n  ),\n  validator_field_types = sc::validator_field_types_sykdomspulsen,\n  validator_field_contents = sc::validator_field_contents_sykdomspulsen,\n  info = \"This db table is used for...\"\n)"},{"path":"tasks.html","id":"task_from_config_v8","chapter":"2 Tasks","heading":"2.5.2 task_from_config_v8","text":"“register” task, use RStudio addin task_from_config.number important things code need highlighting.","code":"\n# tm_run_task(\"example_weather_import_data_from_api\")\nsc::add_task_from_config_v8(\n  name_grouping = \"example_weather\",\n  name_action = \"import_data_from_api\",\n  name_variant = NULL,\n  cores = 1,\n  plan_analysis_fn_name = NULL, # \"PACKAGE::TASK_NAME_plan_analysis\"\n  for_each_plan = plnr::expand_list(\n    location_code = \"county03\" # fhidata::norway_locations_names()[granularity_geo %in% c(\"county\")]$location_code\n  ),\n  for_each_analysis = NULL,\n  universal_argset = NULL,\n  upsert_at_end_of_each_plan = FALSE,\n  insert_at_end_of_each_plan = FALSE,\n  action_fn_name = \"example_weather_import_data_from_api_action\",\n  data_selector_fn_name = \"example_weather_import_data_from_api_data_selector\",\n  schema = list(\n    # input\n\n    # output\n    \"anon_example_weather\" = sc::config$schemas$anon_example_weather\n  ),\n  info = \"This task does...\"\n)"},{"path":"tasks.html","id":"for_each_plan","chapter":"2 Tasks","heading":"2.5.2.1 for_each_plan","text":"for_each_plan expects list. component list correspond plan, values added argset analyses inside plan.example, following code give 4 plans, 1 analysis per plan, analysis containing argset$var_1 argset$var_2 appropriate.always need least 1 plan. simple plan possible :","code":"\nfor_each_plan <- list()\nfor_each_plan[[1]] <- list(\n  var_1 = 1,\n  var_2 = \"a\"\n)\nfor_each_plan[[2]] <- list(\n  var_1 = 2,\n  var_2 = \"b\"\n)\nfor_each_plan[[3]] <- list(\n  var_1 = 1,\n  var_2 = \"a\"\n)\nfor_each_plan[[4]] <- list(\n  var_1 = 2,\n  var_2 = \"b\"\n)\nplnr::expand_list(\n  x = 1\n)\n## [[1]]\n## [[1]]$x\n## [1] 1"},{"path":"tasks.html","id":"plnrexpand_list","chapter":"2 Tasks","heading":"2.5.2.2 plnr::expand_list","text":"plnr::expand_list esentially expand.grid, except return values lists instead data.frame.code simplified follows.","code":"\nfor_each_plan <- plnr::expand_list(\n  var_1 = c(1,2),\n  var_2 = c(\"a\", \"b\")\n)\nfor_each_plan\n## [[1]]\n## [[1]]$var_1\n## [1] 1\n## \n## [[1]]$var_2\n## [1] \"a\"\n## \n## \n## [[2]]\n## [[2]]$var_1\n## [1] 2\n## \n## [[2]]$var_2\n## [1] \"a\"\n## \n## \n## [[3]]\n## [[3]]$var_1\n## [1] 1\n## \n## [[3]]$var_2\n## [1] \"b\"\n## \n## \n## [[4]]\n## [[4]]$var_1\n## [1] 2\n## \n## [[4]]$var_2\n## [1] \"b\""},{"path":"tasks.html","id":"for_each_analysis","chapter":"2 Tasks","heading":"2.5.2.3 for_each_analysis","text":"for_each_plan expects list, generate length(for_each_plan) plans.for_each_analysis , except generate analyses within plans.","code":""},{"path":"tasks.html","id":"universal_argset","chapter":"2 Tasks","heading":"2.5.2.4 universal_argset","text":"named list add values argset analyses.","code":""},{"path":"tasks.html","id":"upsert_at_end_of_each_plan","chapter":"2 Tasks","heading":"2.5.2.5 upsert_at_end_of_each_plan","text":"TRUE schema contains schema called output, returned values action_fn stored upserted schema$output end plan.choose upsert/insert manually within action_fn, can end analysis.","code":""},{"path":"tasks.html","id":"insert_at_end_of_each_plan","chapter":"2 Tasks","heading":"2.5.2.6 insert_at_end_of_each_plan","text":"TRUE schema contains schema called output, returned values action_fn stored inserted schema$output end plan.choose upsert/insert manually within action_fn, can end analysis.","code":""},{"path":"tasks.html","id":"action_fn_name","chapter":"2 Tasks","heading":"2.5.2.7 action_fn_name","text":"character string action_fn, preferably including package name.","code":""},{"path":"tasks.html","id":"data_selector_fn_name","chapter":"2 Tasks","heading":"2.5.2.8 data_selector_fn_name","text":"character string data_selector_fn, preferably including package name.","code":""},{"path":"tasks.html","id":"schema","chapter":"2 Tasks","heading":"2.5.2.9 schema","text":"named list containing schemas used task.","code":""},{"path":"tasks.html","id":"data_selector_fn","chapter":"2 Tasks","heading":"2.5.3 data_selector_fn","text":"Use addins dropdown easily add boilerplate code.data_selector_fn used extract data plan.lines inside (plnr::is_run_directly()){ used help developers. can run code manually/interactively “load” values argset schema.","code":"\nindex_plan <- 1\n\nargset <- sc::tm_get_argset(\"example_weather_import_data_from_api\", index_plan = index_plan)\nschema <- sc::tm_get_schema(\"example_weather_import_data_from_api\")\n\nprint(argset)\n## $`**universal**`\n## [1] \"*\"\n## \n## $`**plan**`\n## [1] \"*\"\n## \n## $location_code\n## [1] \"county03\"\n## \n## $`**analysis**`\n## [1] \"*\"\n## \n## $`**automatic**`\n## [1] \"*\"\n## \n## $index\n## [1] 1\n## \n## $today\n## [1] \"2022-03-01\"\n## \n## $yesterday\n## [1] \"2022-02-28\"\n## \n## $first_analysis\n## [1] TRUE\n## \n## $first_argset\n## [1] TRUE\n## \n## $last_analysis\n## [1] TRUE\n## \n## $last_argset\n## [1] TRUE\nprint(names(schema))\n## [1] \"anon_example_weather\"\n# **** data_selector **** ----\n#' example_weather_import_data_from_api (data selector)\n#' @param argset Argset\n#' @param schema DB Schema\n#' @export\nexample_weather_import_data_from_api_data_selector = function(argset, schema){\n  if(plnr::is_run_directly()){\n    # sc::tm_get_plans_argsets_as_dt(\"example_weather_import_data_from_api\")\n\n    index_plan <- 1\n\n    argset <- sc::tm_get_argset(\"example_weather_import_data_from_api\", index_plan = index_plan)\n    schema <- sc::tm_get_schema(\"example_weather_import_data_from_api\")\n  }\n\n  # find the mid lat/long for the specified location_code\n  gps <- fhimaps::norway_nuts3_map_b2020_default_dt[location_code == argset$location_code,.(\n    lat = mean(lat),\n    long = mean(long)\n  )]\n  \n  # download the forecast for the specified location_code\n  d <- httr::GET(glue::glue(\"https://api.met.no/weatherapi/locationforecast/2.0/classic?lat={gps$lat}&lon={gps$long}\"), httr::content_type_xml())\n  d <- xml2::read_xml(d$content)\n\n  # The variable returned must be a named list\n  retval <- list(\n    \"data\" = d\n  )\n  retval\n}"},{"path":"tasks.html","id":"action_fn","chapter":"2 Tasks","heading":"2.6 action_fn","text":"lines inside (plnr::is_run_directly()){ used help developers. can run code manually/interactively “load” values argset schema.","code":"\nindex_plan <- 1\nindex_analysis <- 1\n\ndata <- sc::tm_get_data(\"example_weather_import_data_from_api\", index_plan = index_plan)\nargset <- sc::tm_get_argset(\"example_weather_import_data_from_api\", index_plan = index_plan, index_analysis = index_analysis)\nschema <- sc::tm_get_schema(\"example_weather_import_data_from_api\")\n\nprint(data)\n## $data\n## {xml_document}\n## <weatherdata noNamespaceSchemaLocation=\"https://schema.api.met.no/schemas/weatherapi-0.4.xsd\" created=\"2022-03-01T10:49:16Z\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\">\n## [1] <meta>\\n  <model name=\"met_public_forecast\" termin=\"2022-03-01T10:00:00Z\" runended=\"2022-03-01T10:10:35Z\" nextrun=\"2022-03-01T11:10:35Z\" from=\" ...\n## [2] <product class=\"pointData\">\\n  <time datatype=\"forecast\" from=\"2022-03-01T10:00:00Z\" to=\"2022-03-01T10:00:00Z\">\\n    <location altitude=\"252\" l ...\nprint(argset)\n## $`**universal**`\n## [1] \"*\"\n## \n## $`**plan**`\n## [1] \"*\"\n## \n## $location_code\n## [1] \"county03\"\n## \n## $`**analysis**`\n## [1] \"*\"\n## \n## $`**automatic**`\n## [1] \"*\"\n## \n## $index\n## [1] 1\n## \n## $today\n## [1] \"2022-03-01\"\n## \n## $yesterday\n## [1] \"2022-02-28\"\n## \n## $first_analysis\n## [1] TRUE\n## \n## $first_argset\n## [1] TRUE\n## \n## $last_analysis\n## [1] TRUE\n## \n## $last_argset\n## [1] TRUE\nprint(names(schema))\n## [1] \"anon_example_weather\"\n# **** action **** ----\n#' example_weather_import_data_from_api (action)\n#' @param data Data\n#' @param argset Argset\n#' @param schema DB Schema\n#' @export\nexample_weather_import_data_from_api_action <- function(data, argset, schema) {\n  # tm_run_task(\"example_weather_import_data_from_api\")\n\n  if(plnr::is_run_directly()){\n    # sc::tm_get_plans_argsets_as_dt(\"example_weather_import_data_from_api\")\n\n    index_plan <- 1\n    index_analysis <- 1\n\n    data <- sc::tm_get_data(\"example_weather_import_data_from_api\", index_plan = index_plan)\n    argset <- sc::tm_get_argset(\"example_weather_import_data_from_api\", index_plan = index_plan, index_analysis = index_analysis)\n    schema <- sc::tm_get_schema(\"example_weather_import_data_from_api\")\n  }\n\n  # code goes here\n  # special case that runs before everything\n  if(argset$first_analysis == TRUE){\n\n  }\n  \n  a <- data$data\n  \n  baz <- xml2::xml_find_all(a, \".//maxTemperature\")\n  res <- vector(\"list\", length = length(baz))\n  for (i in seq_along(baz)) {\n    parent <- xml2::xml_parent(baz[[i]])\n    grandparent <- xml2::xml_parent(parent)\n    time_from <- xml2::xml_attr(grandparent, \"from\")\n    time_to <- xml2::xml_attr(grandparent, \"to\")\n    x <- xml2::xml_find_all(parent, \".//minTemperature\")\n    temp_min <- xml2::xml_attr(x, \"value\")\n    x <- xml2::xml_find_all(parent, \".//maxTemperature\")\n    temp_max <- xml2::xml_attr(x, \"value\")\n    x <- xml2::xml_find_all(parent, \".//precipitation\")\n    precip <- xml2::xml_attr(x, \"value\")\n    res[[i]] <- data.frame(\n      time_from = as.character(time_from),\n      time_to = as.character(time_to),\n      tx = as.numeric(temp_max),\n      tn = as.numeric(temp_min),\n      rr = as.numeric(precip)\n    )\n  }\n  res <- rbindlist(res)\n  res <- res[stringr::str_sub(time_from, 12, 13) %in% c(\"00\", \"06\", \"12\", \"18\")]\n  res[, date := as.Date(stringr::str_sub(time_from, 1, 10))]\n  res[, N := .N, by = date]\n  res <- res[N == 4]\n  res <- res[\n    , \n    .(\n      tg = NA,\n      tx = max(tx),\n      tn = min(tn),\n      rr = sum(rr)\n    ),\n    keyby = .(date)\n  ]\n  \n  # we look at the downloaded data\n  print(\"Data after downloading\")\n  print(res)\n  \n  # we now need to format it\n  res[, granularity_time := \"day\"]\n  res[, sex := \"total\"]\n  res[, age := \"total\"]\n  res[, location_code := argset$location_code]\n  \n  # fill in missing structural variables\n  sc::fill_in_missing_v8(res, border = 2020)\n  \n  # we look at the downloaded data\n  print(\"Data after missing structural variables filled in\")\n  print(res)\n\n  # put data in db table\n  # schema$SCHEMA_NAME$insert_data(d)\n  schema$anon_example_weather$upsert_data(res)\n  # schema$SCHEMA_NAME$drop_all_rows_and_then_upsert_data(d)\n\n  # special case that runs after everything\n  # copy to anon_web?\n  if(argset$last_analysis == TRUE){\n    # sc::copy_into_new_table_where(\n    #   table_from = \"anon_X\",\n    #   table_to = \"anon_webkht\"\n    # )\n  }\n}"},{"path":"tasks.html","id":"run-the-task","chapter":"2 Tasks","heading":"2.7 Run the task","text":"","code":"tm_run_task(\"example_weather_import_data_from_api\")\n## task: example_weather_import_data_from_api\n## Running task=example_weather_import_data_from_api with plans=1 and analyses=1\n## plans=sequential, argset=sequential with cores=1\n## \n[----------------------------------------------------------------------------------------------------------------] 0/1 (  0%) in 00:00:00, eta:  ?s\n## \n[================================================================================================================] 1/1 (100%) in 00:00:00, eta:  0s\n## [1] \"Data after downloading\"\n##          date tg  tx   tn rr\n## 1: 2022-03-02 NA 6.2 -3.0  0\n## 2: 2022-03-03 NA 5.6 -2.3  0\n## 3: 2022-03-04 NA 4.7 -3.3  0\n## 4: 2022-03-05 NA 4.1 -1.9  0\n## 5: 2022-03-06 NA 5.8 -2.9  0\n## 6: 2022-03-07 NA 5.0 -2.6  0\n## 7: 2022-03-08 NA 4.4 -1.1  0\n## 8: 2022-03-09 NA 3.2 -1.4  0\n## [1] \"Data after missing structural variables filled in\"\n##          date tg  tx   tn rr granularity_time   sex   age location_code granularity_geo border isoyearweek    season isoyear isoweek seasonweek\n## 1: 2022-03-02 NA 6.2 -3.0  0              day total total      county03          county   2020     2022-09 2021/2022    2022       9         32\n## 2: 2022-03-03 NA 5.6 -2.3  0              day total total      county03          county   2020     2022-09 2021/2022    2022       9         32\n## 3: 2022-03-04 NA 4.7 -3.3  0              day total total      county03          county   2020     2022-09 2021/2022    2022       9         32\n## 4: 2022-03-05 NA 4.1 -1.9  0              day total total      county03          county   2020     2022-09 2021/2022    2022       9         32\n## 5: 2022-03-06 NA 5.8 -2.9  0              day total total      county03          county   2020     2022-09 2021/2022    2022       9         32\n## 6: 2022-03-07 NA 5.0 -2.6  0              day total total      county03          county   2020     2022-10 2021/2022    2022      10         33\n## 7: 2022-03-08 NA 4.4 -1.1  0              day total total      county03          county   2020     2022-10 2021/2022    2022      10         33\n## 8: 2022-03-09 NA 3.2 -1.4  0              day total total      county03          county   2020     2022-10 2021/2022    2022      10         33\n##    calyear calmonth calyearmonth country_iso3\n## 1:    2022        3     2022-M03          nor\n## 2:    2022        3     2022-M03          nor\n## 3:    2022        3     2022-M03          nor\n## 4:    2022        3     2022-M03          nor\n## 5:    2022        3     2022-M03          nor\n## 6:    2022        3     2022-M03          nor\n## 7:    2022        3     2022-M03          nor\n## 8:    2022        3     2022-M03          nor\n## Task ran in 0 mins"},{"path":"tasks.html","id":"examples-of-different-types-of-tasks","chapter":"2 Tasks","heading":"2.8 Examples of different types of tasks","text":"","code":""},{"path":"tasks.html","id":"importing-data","chapter":"2 Tasks","heading":"2.8.1 Importing data","text":"","code":"\nsc::add_task_from_config_v8(\n  name_grouping = \"example\",\n  name_action = \"import_data\",\n  name_variant = NULL,\n  cores = 1,\n  plan_analysis_fn_name = NULL,\n  for_each_plan = plnr::expand_list(\n    x = 1\n  ),\n  for_each_analysis = NULL,\n  universal_argset = list(\n    folder = sc::path(\"input\", \"example\")\n  ),\n  upsert_at_end_of_each_plan = FALSE,\n  insert_at_end_of_each_plan = FALSE,\n  action_fn_name = \"example_import_data_action\",\n  data_selector_fn_name = \"example_import_data_data_selector\",\n  schema = list(\n    # input\n\n    # output\n    \"output\" = sc::config$schemas$output\n  ),\n  info = \"This task does...\"\n)"},{"path":"tasks.html","id":"analysis","chapter":"2 Tasks","heading":"2.8.2 Analysis","text":"","code":"\nsc::add_task_from_config_v8(\n  name_grouping = \"example\",\n  name_action = \"analysis\",\n  name_variant = NULL,\n  cores = 1,\n  plan_analysis_fn_name = NULL, \n  for_each_plan = plnr::expand_list(\n    location_code = fhidata::norway_locations_names()[granularity_geo %in% c(\"county\")]$location_code\n  ),\n  for_each_analysis = NULL,\n  universal_argset = NULL,\n  upsert_at_end_of_each_plan = FALSE,\n  insert_at_end_of_each_plan = FALSE,\n  action_fn_name = \"example_analysis_action\",\n  data_selector_fn_name = \"example_analysis_data_selector\",\n  schema = list(\n    # input\n    \"input\" = sc::config$schemas$input,\n\n    # output\n    \"output\" = sc::config$schemas$output\n  ),\n  info = \"This task does...\"\n)"},{"path":"tasks.html","id":"exporting-multiple-sets-of-results","chapter":"2 Tasks","heading":"2.8.3 Exporting multiple sets of results","text":"","code":"\nsc::add_task_from_config_v8(\n  name_grouping = \"example\",\n  name_action = \"export_results\",\n  name_variant = NULL,\n  cores = 1,\n  plan_analysis_fn_name = NULL, \n  for_each_plan = plnr::expand_list(\n    location_code = fhidata::norway_locations_names()[granularity_geo %in% c(\"county\")]$location_code\n  ),\n  for_each_analysis = NULL,\n  universal_argset = list(\n    folder = sc::path(\"output\", \"example\")\n  ),\n  upsert_at_end_of_each_plan = FALSE,\n  insert_at_end_of_each_plan = FALSE,\n  action_fn_name = \"example_export_results_action\",\n  data_selector_fn_name = \"example_export_results_data_selector\",\n  schema = list(\n    # input\n    \"input\" = sc::config$schemas$input\n\n    # output\n  ),\n  info = \"This task does...\"\n)"},{"path":"tasks.html","id":"exporting-combined-results","chapter":"2 Tasks","heading":"2.8.4 Exporting combined results","text":"","code":"\nsc::add_task_from_config_v8(\n  name_grouping = \"example\",\n  name_action = \"export_results\",\n  name_variant = NULL,\n  cores = 1,\n  plan_analysis_fn_name = NULL, \n  for_each_plan = plnr::expand_list(\n    x = 1\n  ),\n  for_each_analysis = NULL,\n  universal_argset = list(\n    folder = sc::path(\"output\", \"example\"),\n    granularity_geos = c(\"nation\", \"county\")\n  ),\n  upsert_at_end_of_each_plan = FALSE,\n  insert_at_end_of_each_plan = FALSE,\n  action_fn_name = \"example_export_results_action\",\n  data_selector_fn_name = \"example_export_results_data_selector\",\n  schema = list(\n    # input\n    \"input\" = sc::config$schemas$input\n\n    # output\n  ),\n  info = \"This task does...\"\n)"},{"path":"file-layout.html","id":"file-layout","chapter":"3 File Layout","heading":"3 File Layout","text":"","code":""},{"path":"file-layout.html","id":"introduction-2","chapter":"3 File Layout","heading":"3.1 Introduction","text":"Implementing Sykdomspulsen Core requires number functions called correct order. make simple possible, provided skeleton implementation https://github.com/sykdomspulsen-org/scskeletonWe suggest clone GitHub repo server, global find/replace scskeleton name want R package.Descriptions required files/functions detailed .","code":""},{"path":"file-layout.html","id":"env_and_namespace.r","chapter":"3 File Layout","heading":"3.2 00_env_and_namespace.r","text":"https://github.com/sykdomspulsen-org/scskeleton/blob/main/R/00_env_and_namespace.r","code":"## https://github.com/sykdomspulsen-org/scskeleton/blob/main/R/00_env_and_namespace.r\n## \n##  1 | # ******************************************************************************\n##  2 | # ******************************************************************************\n##  3 | #\n##  4 | # 00_env_and_namespace.r\n##  5 | #\n##  6 | # PURPOSE 1:\n##  7 | #   Use roxygen2 to import ggplot2, data.table, %>%, and %<>% into the namespace,\n##  8 | #   because these are the most commonly used packages/functions.\n##  9 | #\n## 10 | # PURPOSE 2:\n## 11 | #   Declaring our own \"tm_run_task\" inside this package, as a wrapper around\n## 12 | #   sc::tm_run_task.\n## 13 | #\n## 14 | #   We cannot run sc::tm_run_task directly, because we need to load all of the\n## 15 | #   database connections, db schemas, tasks, etc. *before* we run the task.\n## 16 | #   Hence, this wrapper ensures that all of this package's configs files are\n## 17 | #   loaded via OURPACKAGE::.onLoad() first, and then sc::tm_run_task can run.\n## 18 | #\n## 19 | # PURPOSE 3:\n## 20 | #   Declaration of environments that can be used globally.\n## 21 | #\n## 22 | # PURPOSE 4:\n## 23 | #   Fix issues/integration with other packages.\n## 24 | #\n## 25 | #   Most notably is the issue with rmarkdown, where an error is thrown when\n## 26 | #   rendering multiple rmarkdown documents in parallel.\n## 27 | #\n## 28 | # ******************************************************************************\n## 29 | # ******************************************************************************\n## 30 | \n## 31 | #' @import ggplot2\n## 32 | #' @import data.table\n## 33 | #' @importFrom magrittr %>% %<>%\n## 34 | 1\n## 35 | \n## 36 | #' Shortcut to run task\n## 37 | #'\n## 38 | #' This task is needed to ensure that all the definitions/db schemas/tasks/etc\n## 39 | #' are loaded from the package scskeleton. We cannot run sc::tm_run_task directly,\n## 40 | #' because we need to load all of the database connections, db schemas, tasks,\n## 41 | #' etc. *before* we run the task. Hence, this wrapper ensures that all of this\n## 42 | #' package's configs files are loaded via OURPACKAGE::.onLoad() first, and then\n## 43 | #' sc::tm_run_task can run.\n## 44 | #'\n## 45 | #' @param task_name Name of the task\n## 46 | #' @param index_plan Not used\n## 47 | #' @param index_analysis Not used\n## 48 | #' @export\n## 49 | tm_run_task <- function(task_name, index_plan = NULL, index_analysis = NULL) {\n## 50 |   sc::tm_run_task(\n## 51 |     task_name = task_name,\n## 52 |     index_plan = index_plan,\n## 53 |     index_analysis = index_analysis\n## 54 |   )\n## 55 | }\n## 56 | \n## 57 | #' Declaration of environments that can be used globally\n## 58 | #' @export config\n## 59 | config <- new.env()\n## 60 | \n## 61 | # https://github.com/rstudio/rmarkdown/issues/1632\n## 62 | # An error is thrown when rendering multiple rmarkdown documents in parallel.\n## 63 | clean_tmpfiles_mod <- function() {\n## 64 |   # message(\"Calling clean_tmpfiles_mod()\")\n## 65 | }"},{"path":"file-layout.html","id":"definitions.r","chapter":"3 File Layout","heading":"3.3 01_definitions.r","text":"https://github.com/sykdomspulsen-org/scskeleton/blob/main/R/01_definitions.r","code":"## https://github.com/sykdomspulsen-org/scskeleton/blob/main/R/01_definitions.r\n## \n##  1 | # ******************************************************************************\n##  2 | # ******************************************************************************\n##  3 | #\n##  4 | # 01_definitions.r\n##  5 | #\n##  6 | # PURPOSE 1:\n##  7 | #   Set global definitions that are used throughout the package, and further\n##  8 | #   (e.g. in shiny/plumber creations).\n##  9 | #\n## 10 | #   Examples of global definitions are:\n## 11 | #     - Border years\n## 12 | #     - Age definitions\n## 13 | #     - Diagnosis mappings (e.g. \"R80\" = \"Influenza\")\n## 14 | #\n## 15 | # ******************************************************************************\n## 16 | # ******************************************************************************\n## 17 | \n## 18 | #' Set global definitions\n## 19 | set_definitions <- function() {\n## 20 | \n## 21 |   # Norway's last redistricting occurred 2020-01-01\n## 22 |   config$border <- 2020\n## 23 | \n## 24 |   # fhidata needs to know which border is in use\n## 25 |   # fhidata should also replace the population of 1900 with the current year,\n## 26 |   # because year = 1900 is shorthand for granularity_geo = \"total\".\n## 27 |   # This means that it is more appropriate to use the current year's population\n## 28 |   # for year = 1900.\n## 29 |   fhidata::set_config(\n## 30 |     border = config$border,\n## 31 |     use_current_year_as_1900_pop = TRUE\n## 32 |   )\n## 33 | }"},{"path":"file-layout.html","id":"permissions.r","chapter":"3 File Layout","heading":"3.4 02_permissions.r","text":"https://github.com/sykdomspulsen-org/scskeleton/blob/main/R/02_permissions.r","code":"## https://github.com/sykdomspulsen-org/scskeleton/blob/main/R/02_permissions.r\n## \n##  1 | # ******************************************************************************\n##  2 | # ******************************************************************************\n##  3 | #\n##  4 | # 02_permissions.r\n##  5 | #\n##  6 | # PURPOSE 1:\n##  7 | #   Set permissions that can be used in this package.\n##  8 | #\n##  9 | # PURPOSE 2:\n## 10 | #   Permissions are a way of ensuring that a task only runs once per hour/day/week.\n## 11 | #   This can be useful when you want to be 100% sure that you don't want to spam\n## 12 | #   emails to your recipients.\n## 13 | #\n## 14 | # PURPOSE 3:\n## 15 | #   Permissions can also be used to differentiate between \"production days\" and\n## 16 | #   \"preliminary days\". This can be useful when you have different email lists\n## 17 | #   for production days (everyone) and preliminary days (a smaller group).\n## 18 | #\n## 19 | # ******************************************************************************\n## 20 | # ******************************************************************************\n## 21 | \n## 22 | set_permissions <- function() {\n## 23 |   # sc::add_permission(\n## 24 |   #   name = \"khtemails_send_emails\",\n## 25 |   #   permission = sc::Permission$new(\n## 26 |   #     key = \"khtemails_send_emails\",\n## 27 |   #     value = as.character(lubridate::today()),  # one time per day\n## 28 |   #     production_days = c(3) # wed, send to everyone, otherwise prelim\n## 29 |   #   )\n## 30 |   # )\n## 31 | }"},{"path":"file-layout.html","id":"db_schemas.r","chapter":"3 File Layout","heading":"3.5 03_db_schemas.r","text":"https://github.com/sykdomspulsen-org/scskeleton/blob/main/R/03_db_schemas.r","code":"## https://github.com/sykdomspulsen-org/scskeleton/blob/main/R/03_db_schemas.r\n## \n##   1 | # ******************************************************************************\n##   2 | # ******************************************************************************\n##   3 | #\n##   4 | # 03_db_schemas.r\n##   5 | #\n##   6 | # PURPOSE 1:\n##   7 | #   Set db schemas that are used throughout the package.\n##   8 | #\n##   9 | #   These are basically all of the database tables that you will be writing to,\n##  10 | #   and reading from.\n##  11 | #\n##  12 | # ******************************************************************************\n##  13 | # ******************************************************************************\n##  14 | \n##  15 | set_db_schemas <- function() {\n##  16 |   # __________ ----\n##  17 |   # Weather  ----\n##  18 |   ## > anon_example_weather_rawdata ----\n##  19 |   sc::add_schema_v8(\n##  20 |     name_access = c(\"anon\"),\n##  21 |     name_grouping = \"example_weather\",\n##  22 |     name_variant = \"rawdata\",\n##  23 |     db_configs = sc::config$db_configs,\n##  24 |     field_types =  c(\n##  25 |       \"granularity_time\" = \"TEXT\",\n##  26 |       \"granularity_geo\" = \"TEXT\",\n##  27 |       \"country_iso3\" = \"TEXT\",\n##  28 |       \"location_code\" = \"TEXT\",\n##  29 |       \"border\" = \"INTEGER\",\n##  30 |       \"age\" = \"TEXT\",\n##  31 |       \"sex\" = \"TEXT\",\n##  32 | \n##  33 |       \"date\" = \"DATE\",\n##  34 | \n##  35 |       \"isoyear\" = \"INTEGER\",\n##  36 |       \"isoweek\" = \"INTEGER\",\n##  37 |       \"isoyearweek\" = \"TEXT\",\n##  38 |       \"season\" = \"TEXT\",\n##  39 |       \"seasonweek\" = \"DOUBLE\",\n##  40 | \n##  41 |       \"calyear\" = \"INTEGER\",\n##  42 |       \"calmonth\" = \"INTEGER\",\n##  43 |       \"calyearmonth\" = \"TEXT\",\n##  44 | \n##  45 |       \"temp_max\" = \"DOUBLE\",\n##  46 |       \"temp_min\" = \"DOUBLE\",\n##  47 |       \"precip\" = \"DOUBLE\"\n##  48 |     ),\n##  49 |     keys = c(\n##  50 |       \"granularity_time\",\n##  51 |       \"location_code\",\n##  52 |       \"date\",\n##  53 |       \"age\",\n##  54 |       \"sex\"\n##  55 |     ),\n##  56 |     censors = list(\n##  57 |       anon = list(\n##  58 | \n##  59 |       )\n##  60 |     ),\n##  61 |     validator_field_types = sc::validator_field_types_sykdomspulsen,\n##  62 |     validator_field_contents = sc::validator_field_contents_sykdomspulsen,\n##  63 |     info = \"This db table is used for...\"\n##  64 |   )\n##  65 | \n##  66 |   ## > anon_example_weather_data ----\n##  67 |   sc::add_schema_v8(\n##  68 |     name_access = c(\"anon\"),\n##  69 |     name_grouping = \"example_weather\",\n##  70 |     name_variant = \"data\",\n##  71 |     db_configs = sc::config$db_configs,\n##  72 |     field_types =  c(\n##  73 |       \"granularity_time\" = \"TEXT\",\n##  74 |       \"granularity_geo\" = \"TEXT\",\n##  75 |       \"country_iso3\" = \"TEXT\",\n##  76 |       \"location_code\" = \"TEXT\",\n##  77 |       \"border\" = \"INTEGER\",\n##  78 |       \"age\" = \"TEXT\",\n##  79 |       \"sex\" = \"TEXT\",\n##  80 | \n##  81 |       \"date\" = \"DATE\",\n##  82 | \n##  83 |       \"isoyear\" = \"INTEGER\",\n##  84 |       \"isoweek\" = \"INTEGER\",\n##  85 |       \"isoyearweek\" = \"TEXT\",\n##  86 |       \"season\" = \"TEXT\",\n##  87 |       \"seasonweek\" = \"DOUBLE\",\n##  88 | \n##  89 |       \"calyear\" = \"INTEGER\",\n##  90 |       \"calmonth\" = \"INTEGER\",\n##  91 |       \"calyearmonth\" = \"TEXT\",\n##  92 | \n##  93 |       \"temp_max\" = \"DOUBLE\",\n##  94 |       \"temp_min\" = \"DOUBLE\",\n##  95 |       \"precip\" = \"DOUBLE\"\n##  96 |     ),\n##  97 |     keys = c(\n##  98 |       \"granularity_time\",\n##  99 |       \"location_code\",\n## 100 |       \"date\",\n## 101 |       \"age\",\n## 102 |       \"sex\"\n## 103 |     ),\n## 104 |     censors = list(\n## 105 |       anon = list(\n## 106 | \n## 107 |       )\n## 108 |     ),\n## 109 |     validator_field_types = sc::validator_field_types_sykdomspulsen,\n## 110 |     validator_field_contents = sc::validator_field_contents_sykdomspulsen,\n## 111 |     info = \"This db table is used for...\"\n## 112 |   )\n## 113 | }"},{"path":"file-layout.html","id":"tasks.r","chapter":"3 File Layout","heading":"3.6 04_tasks.r","text":"https://github.com/sykdomspulsen-org/scskeleton/blob/main/R/04_tasks.r","code":"## https://github.com/sykdomspulsen-org/scskeleton/blob/main/R/04_tasks.r\n## \n##   1 | # ******************************************************************************\n##   2 | # ******************************************************************************\n##   3 | #\n##   4 | # 04_tasks.r\n##   5 | #\n##   6 | # PURPOSE 1:\n##   7 | #   Set all the tasks that are run by the package.\n##   8 | #\n##   9 | #   These are basically all of the \"things\" that you want to do.\n##  10 | #   E.g. Downloading data, cleaning data, importing data, analyzing data,\n##  11 | #   making Excel files, making docx/pdf reports, sending emails, etc.\n##  12 | #\n##  13 | # ******************************************************************************\n##  14 | # ******************************************************************************\n##  15 | \n##  16 | set_tasks <- function() {\n##  17 |   # __________ ----\n##  18 |   # Weather  ----\n##  19 |   ## > weather_download_and_import_rawdata ----\n##  20 |   # tm_run_task(\"weather_download_and_import_rawdata\")\n##  21 |   sc::add_task_from_config_v8(\n##  22 |     name_grouping = \"weather\",\n##  23 |     name_action = \"download_and_import_rawdata\",\n##  24 |     name_variant = NULL,\n##  25 |     cores = 1,\n##  26 |     plan_analysis_fn_name = NULL,\n##  27 |     for_each_plan = plnr::expand_list(\n##  28 |       location_code = fhidata::norway_locations_names()[granularity_geo %in% c(\"municip\")]$location_code\n##  29 |     ),\n##  30 |     for_each_analysis = NULL,\n##  31 |     universal_argset = NULL,\n##  32 |     upsert_at_end_of_each_plan = FALSE,\n##  33 |     insert_at_end_of_each_plan = FALSE,\n##  34 |     action_fn_name = \"scskeleton::weather_download_and_import_rawdata_action\",\n##  35 |     data_selector_fn_name = \"scskeleton::weather_download_and_import_rawdata_data_selector\",\n##  36 |     schema = list(\n##  37 |       # input\n##  38 | \n##  39 |       # output\n##  40 |       \"anon_example_weather_rawdata\" = sc::config$schemas$anon_example_weather_rawdata\n##  41 |     ),\n##  42 |     info = \"This task downloads and imports the raw weather data from MET's API at the municipal level\"\n##  43 |   )\n##  44 | \n##  45 |   ## > weather_clean_data ----\n##  46 |   # tm_run_task(\"weather_clean_data\")\n##  47 |   sc::add_task_from_config_v8(\n##  48 |     name_grouping = \"weather\",\n##  49 |     name_action = \"clean_data\",\n##  50 |     name_variant = NULL,\n##  51 |     cores = 1,\n##  52 |     plan_analysis_fn_name = NULL,\n##  53 |     for_each_plan = plnr::expand_list(\n##  54 |       x = 1\n##  55 |     ),\n##  56 |     for_each_analysis = NULL,\n##  57 |     universal_argset = NULL,\n##  58 |     upsert_at_end_of_each_plan = FALSE,\n##  59 |     insert_at_end_of_each_plan = FALSE,\n##  60 |     action_fn_name = \"scskeleton::weather_clean_data_action\",\n##  61 |     data_selector_fn_name = \"scskeleton::weather_clean_data_data_selector\",\n##  62 |     schema = list(\n##  63 |       # input\n##  64 |       \"anon_example_weather_rawdata\" = sc::config$schemas$anon_example_weather_rawdata,\n##  65 | \n##  66 |       # output\n##  67 |       \"anon_example_weather_data\" = sc::config$schemas$anon_example_weather_data\n##  68 |     ),\n##  69 |     info = \"This task cleans the raw data and aggregates it to county and national level\"\n##  70 |   )\n##  71 | \n##  72 |   ## > weather_clean_data ----\n##  73 |   # tm_run_task(\"weather_export_plots\")\n##  74 |   sc::add_task_from_config_v8(\n##  75 |     name_grouping = \"weather\",\n##  76 |     name_action = \"export_plots\",\n##  77 |     name_variant = NULL,\n##  78 |     cores = 1,\n##  79 |     plan_analysis_fn_name = NULL,\n##  80 |     for_each_plan = plnr::expand_list(\n##  81 |       location_code = fhidata::norway_locations_names()[granularity_geo %in% c(\"county\")]$location_code\n##  82 |     ),\n##  83 |     for_each_analysis = NULL,\n##  84 |     universal_argset = list(\n##  85 |       output_dir = tempdir(),\n##  86 |       output_filename = \"weather_{argset$location_code}.png\",\n##  87 |       output_absolute_path = fs::path(\"{argset$output_dir}\", \"{argset$output_filename}\")\n##  88 |     ),\n##  89 |     upsert_at_end_of_each_plan = FALSE,\n##  90 |     insert_at_end_of_each_plan = FALSE,\n##  91 |     action_fn_name = \"scskeleton::weather_export_plots_action\",\n##  92 |     data_selector_fn_name = \"scskeleton::weather_export_plots_data_selector\",\n##  93 |     schema = list(\n##  94 |       # input\n##  95 |       \"anon_example_weather_data\" = sc::config$schemas$anon_example_weather_data\n##  96 | \n##  97 |       # output\n##  98 |     ),\n##  99 |     info = \"This task ploduces plots\"\n## 100 |   )\n## 101 | }"},{"path":"file-layout.html","id":"deliverables.r","chapter":"3 File Layout","heading":"3.7 05_deliverables.r","text":"https://github.com/sykdomspulsen-org/scskeleton/blob/main/R/05_deliverables.r","code":"## https://github.com/sykdomspulsen-org/scskeleton/blob/main/R/05_deliverables.r\n## \n##  1 | # ******************************************************************************\n##  2 | # ******************************************************************************\n##  3 | #\n##  4 | # 05_deliverables.r\n##  5 | #\n##  6 | # PURPOSE 1:\n##  7 | #   Set all the deliverables that team members are supposed to manually do/check\n##  8 | #   every day/week/month.\n##  9 | #\n## 10 | # ******************************************************************************\n## 11 | # ******************************************************************************\n## 12 | \n## 13 | set_deliverables <- function() {\n## 14 | \n## 15 | }"},{"path":"file-layout.html","id":"config.r","chapter":"3 File Layout","heading":"3.8 06_config.r","text":"https://github.com/sykdomspulsen-org/scskeleton/blob/main/R/06_config.r","code":"## https://github.com/sykdomspulsen-org/scskeleton/blob/main/R/06_config.r\n## \n##  1 | # ******************************************************************************\n##  2 | # ******************************************************************************\n##  3 | #\n##  4 | # 06_config.r\n##  5 | #\n##  6 | # PURPOSE 1:\n##  7 | #   Call all the functions defined in 01, 02, 03, 04, and 05 in the correct order.\n##  8 | #\n##  9 | # PURPOSE 2:\n## 10 | #   Set all necessary configs that do not belong anywhere else.\n## 11 | #\n## 12 | #   E.g. Formatting for progress bars.\n## 13 | #\n## 14 | # ******************************************************************************\n## 15 | # ******************************************************************************\n## 16 | \n## 17 | set_config <- function() {\n## 18 |   # 01_definitions.r\n## 19 |   set_definitions()\n## 20 | \n## 21 |   # 02_permissions.r\n## 22 |   set_permissions()\n## 23 | \n## 24 |   # 03_db_schemas.r\n## 25 |   set_db_schemas()\n## 26 | \n## 27 |   # 04_tasks.r\n## 28 |   set_tasks()\n## 29 | \n## 30 |   # 05_deliverables.r\n## 31 |   set_deliverables()\n## 32 | \n## 33 |   # 06_config.r\n## 34 |   set_progressr()\n## 35 | }\n## 36 | \n## 37 | set_progressr <- function() {\n## 38 |   progressr::handlers(progressr::handler_progress(\n## 39 |     format = \"[:bar] :current/:total (:percent) in :elapsedfull, eta: :eta\",\n## 40 |     clear = FALSE\n## 41 |   ))\n## 42 | }"},{"path":"file-layout.html","id":"onload.r","chapter":"3 File Layout","heading":"3.9 07_onLoad.r","text":"https://github.com/sykdomspulsen-org/scskeleton/blob/main/R/07_onLoad.r","code":"## https://github.com/sykdomspulsen-org/scskeleton/blob/main/R/07_onLoad.r\n## \n##  1 | # ******************************************************************************\n##  2 | # ******************************************************************************\n##  3 | #\n##  4 | # 07_onLoad.r\n##  5 | #\n##  6 | # PURPOSE 1:\n##  7 | #   Initializing everything that happens when the package is loaded.\n##  8 | #\n##  9 | #   E.g. Calling bash scripts that authenticate against Kerebros, setting the\n## 10 | #   configs as defined in 06_config.r.\n## 11 | #\n## 12 | # ******************************************************************************\n## 13 | # ******************************************************************************\n## 14 | \n## 15 | .onLoad <- function(libname, pkgname) {\n## 16 |   # Mechanism to authenticate as necessary (e.g. Kerebros)\n## 17 |   try(system2(\"/bin/authenticate.sh\", stdout = NULL), TRUE)\n## 18 | \n## 19 |   # 5_config.r\n## 20 |   set_config()\n## 21 | \n## 22 |   # https://github.com/rstudio/rmarkdown/issues/1632\n## 23 |   assignInNamespace(\"clean_tmpfiles\", clean_tmpfiles_mod, ns = \"rmarkdown\")\n## 24 | \n## 25 |   invisible()\n## 26 | }"},{"path":"file-layout.html","id":"onattach.r","chapter":"3 File Layout","heading":"3.10 08_onAttach.r","text":"https://github.com/sykdomspulsen-org/scskeleton/blob/main/R/08_onAttach.r","code":"## https://github.com/sykdomspulsen-org/scskeleton/blob/main/R/08_onAttach.r\n## \n##  1 | # ******************************************************************************\n##  2 | # ******************************************************************************\n##  3 | #\n##  4 | # 08_onAttach.r\n##  5 | #\n##  6 | # PURPOSE 1:\n##  7 | #   What you want to happen when someone types library(yourpackage)\n##  8 | #\n##  9 | # ******************************************************************************\n## 10 | # ******************************************************************************\n## 11 | \n## 12 | .onAttach <- function(libname, pkgname) {\n## 13 | \n## 14 | }"},{"path":"file-layout.html","id":"util_.r","chapter":"3 File Layout","heading":"3.11 99_util_*.r","text":"https://github.com/sykdomspulsen-org/scskeleton/blob/main/R/99_util_no_data_plot.r","code":"## https://github.com/sykdomspulsen-org/scskeleton/blob/main/R/99_util_no_data_plot.r\n## \n##  1 | # ******************************************************************************\n##  2 | # ******************************************************************************\n##  3 | #\n##  4 | # 99_util_*.r\n##  5 | #\n##  6 | # PURPOSE 1:\n##  7 | #   Utility functions that are used across multiple tasks\n##  8 | #\n##  9 | # ******************************************************************************\n## 10 | # ******************************************************************************\n## 11 | \n## 12 | no_data_plot <- function(){\n## 13 |   data=data.frame(x=0,y=0)\n## 14 |   q <- ggplot(data=data)\n## 15 |   q <- q + theme_void()\n## 16 |   q <- q + annotate(\"text\", label=glue::glue(\"Ikke noe data {fhi::nb$aa} vise\"), x=0, y=0, size=10)\n## 17 |   q\n## 18 | }"},{"path":"file-layout.html","id":"task-files","chapter":"3 File Layout","heading":"3.12 Task files","text":"Task files placed .r files names.","code":""},{"path":"file-layout.html","id":"weather_download_and_import_rawdata.r","chapter":"3 File Layout","heading":"3.12.1 weather_download_and_import_rawdata.r","text":"https://github.com/sykdomspulsen-org/scskeleton/blob/main/R/weather_download_and_import_rawdata.r","code":"## https://github.com/sykdomspulsen-org/scskeleton/blob/main/R/weather_download_and_import_rawdata.r\n## \n##   1 | # **** action **** ----\n##   2 | #' weather_download_and_import_rawdata (action)\n##   3 | #' @param data Data\n##   4 | #' @param argset Argset\n##   5 | #' @param schema DB Schema\n##   6 | #' @export\n##   7 | weather_download_and_import_rawdata_action <- function(data, argset, schema) {\n##   8 |   # tm_run_task(\"weather_download_and_import_rawdata\")\n##   9 | \n##  10 |   if (plnr::is_run_directly()) {\n##  11 |     # sc::tm_get_plans_argsets_as_dt(\"weather_download_and_import_rawdata\")\n##  12 | \n##  13 |     index_plan <- 1\n##  14 |     index_analysis <- 1\n##  15 | \n##  16 |     data <- sc::tm_get_data(\"weather_download_and_import_rawdata\", index_plan = index_plan)\n##  17 |     argset <- sc::tm_get_argset(\"weather_download_and_import_rawdata\", index_plan = index_plan, index_analysis = index_analysis)\n##  18 |     schema <- sc::tm_get_schema(\"weather_download_and_import_rawdata\")\n##  19 |   }\n##  20 | \n##  21 |   # special case that runs before everything\n##  22 |   if (argset$first_analysis == TRUE) {\n##  23 | \n##  24 |   }\n##  25 | \n##  26 |   a <- data$data\n##  27 | \n##  28 |   baz <- xml2::xml_find_all(a, \".//maxTemperature\")\n##  29 |   res <- vector(\"list\", length = length(baz))\n##  30 |   for (i in seq_along(baz)) {\n##  31 |     parent <- xml2::xml_parent(baz[[i]])\n##  32 |     grandparent <- xml2::xml_parent(parent)\n##  33 |     time_from <- xml2::xml_attr(grandparent, \"from\")\n##  34 |     time_to <- xml2::xml_attr(grandparent, \"to\")\n##  35 |     x <- xml2::xml_find_all(parent, \".//minTemperature\")\n##  36 |     temp_min <- xml2::xml_attr(x, \"value\")\n##  37 |     x <- xml2::xml_find_all(parent, \".//maxTemperature\")\n##  38 |     temp_max <- xml2::xml_attr(x, \"value\")\n##  39 |     x <- xml2::xml_find_all(parent, \".//precipitation\")\n##  40 |     precip <- xml2::xml_attr(x, \"value\")\n##  41 |     res[[i]] <- data.frame(\n##  42 |       time_from = as.character(time_from),\n##  43 |       time_to = as.character(time_to),\n##  44 |       temp_max = as.numeric(temp_max),\n##  45 |       temp_min = as.numeric(temp_min),\n##  46 |       precip = as.numeric(precip)\n##  47 |     )\n##  48 |   }\n##  49 |   res <- rbindlist(res)\n##  50 |   res <- res[stringr::str_sub(time_from, 12, 13) %in% c(\"00\", \"06\", \"12\", \"18\")]\n##  51 |   res[, date := as.Date(stringr::str_sub(time_from, 1, 10))]\n##  52 |   res[, N := .N, by = date]\n##  53 |   res <- res[N == 4]\n##  54 |   res <- res[\n##  55 |     ,\n##  56 |     .(\n##  57 |       temp_max = max(temp_max),\n##  58 |       temp_min = min(temp_min),\n##  59 |       precip = sum(precip)\n##  60 |     ),\n##  61 |     keyby = .(date)\n##  62 |   ]\n##  63 | \n##  64 |   # we look at the downloaded data\n##  65 |   # res\n##  66 | \n##  67 |   # we now need to format it\n##  68 |   res[, granularity_time := \"day\"]\n##  69 |   res[, sex := \"total\"]\n##  70 |   res[, age := \"total\"]\n##  71 |   res[, location_code := argset$location_code]\n##  72 | \n##  73 |   # fill in missing structural variables\n##  74 |   sc::fill_in_missing_v8(res, border = 2020)\n##  75 | \n##  76 |   # we look at the downloaded data\n##  77 |   # res\n##  78 | \n##  79 |   # put data in db table\n##  80 |   schema$anon_example_weather_rawdata$insert_data(res)\n##  81 | \n##  82 |   # special case that runs after everything\n##  83 |   if (argset$last_analysis == TRUE) {\n##  84 | \n##  85 |   }\n##  86 | }\n##  87 | \n##  88 | # **** data_selector **** ----\n##  89 | #' weather_download_and_import_rawdata (data selector)\n##  90 | #' @param argset Argset\n##  91 | #' @param schema DB Schema\n##  92 | #' @export\n##  93 | weather_download_and_import_rawdata_data_selector <- function(argset, schema) {\n##  94 |   if (plnr::is_run_directly()) {\n##  95 |     # sc::tm_get_plans_argsets_as_dt(\"weather_download_and_import_rawdata\")\n##  96 | \n##  97 |     index_plan <- 1\n##  98 | \n##  99 |     argset <- sc::tm_get_argset(\"weather_download_and_import_rawdata\", index_plan = index_plan)\n## 100 |     schema <- sc::tm_get_schema(\"weather_download_and_import_rawdata\")\n## 101 |   }\n## 102 | \n## 103 |   # find the mid lat/long for the specified location_code\n## 104 |   gps <- fhimaps::norway_lau2_map_b2020_default_dt[location_code == argset$location_code,.(\n## 105 |     lat = mean(lat),\n## 106 |     long = mean(long)\n## 107 |   )]\n## 108 | \n## 109 |   # download the forecast for the specified location_code\n## 110 |   d <- httr::GET(glue::glue(\"https://api.met.no/weatherapi/locationforecast/2.0/classic?lat={gps$lat}&lon={gps$long}\"), httr::content_type_xml())\n## 111 |   d <- xml2::read_xml(d$content)\n## 112 | \n## 113 |   # The variable returned must be a named list\n## 114 |   retval <- list(\n## 115 |     \"data\" = d\n## 116 |   )\n## 117 | \n## 118 |   retval\n## 119 | }\n## 120 | \n## 121 | # **** functions **** ----"},{"path":"file-layout.html","id":"weather_clean_data.r","chapter":"3 File Layout","heading":"3.12.2 weather_clean_data.r","text":"https://github.com/sykdomspulsen-org/scskeleton/blob/main/R/weather_clean_data.r","code":"## https://github.com/sykdomspulsen-org/scskeleton/blob/main/R/weather_clean_data.r\n## \n##   1 | # **** action **** ----\n##   2 | #' weather_clean_data (action)\n##   3 | #' @param data Data\n##   4 | #' @param argset Argset\n##   5 | #' @param schema DB Schema\n##   6 | #' @export\n##   7 | weather_clean_data_action <- function(data, argset, schema) {\n##   8 |   # tm_run_task(\"weather_clean_data\")\n##   9 | \n##  10 |   if (plnr::is_run_directly()) {\n##  11 |     # sc::tm_get_plans_argsets_as_dt(\"weather_clean_data\")\n##  12 | \n##  13 |     index_plan <- 1\n##  14 |     index_analysis <- 1\n##  15 | \n##  16 |     data <- sc::tm_get_data(\"weather_clean_data\", index_plan = index_plan)\n##  17 |     argset <- sc::tm_get_argset(\"weather_clean_data\", index_plan = index_plan, index_analysis = index_analysis)\n##  18 |     schema <- sc::tm_get_schema(\"weather_clean_data\")\n##  19 |   }\n##  20 | \n##  21 |   # special case that runs before everything\n##  22 |   if (argset$first_analysis == TRUE) {\n##  23 | \n##  24 |   }\n##  25 | \n##  26 |   # make sure there's no missing data via the creation of a skeleton\n##  27 |   # https://folkehelseinstituttet.github.io/fhidata/articles/Skeletons.html\n##  28 | \n##  29 |   # Create a variable (possibly a list) to hold the data\n##  30 |   d_agg <- list()\n##  31 |   d_agg$day_municip <- copy(data$day_municip)\n##  32 | \n##  33 |   # Pull out important dates\n##  34 |   date_min <- min(d_agg$day_municip$date, na.rm = T)\n##  35 |   date_max <- max(d_agg$day_municip$date, na.rm = T)\n##  36 | \n##  37 |   # Create `multiskeleton`\n##  38 |   # granularity_geo should have the following groups:\n##  39 |   # - nodata (when no data is available, and there is no \"finer\" data available to aggregate up)\n##  40 |   # - all levels of granularity_geo where you have data available\n##  41 |   # If you do not have data for a specific granularity_geo, but there is \"finer\" data available\n##  42 |   # then you should not include this granularity_geo in the multiskeleton, because you will create\n##  43 |   # it later when you aggregate up your data (baregion)\n##  44 |   multiskeleton_day <- fhidata::make_skeleton(\n##  45 |     date_min = date_min,\n##  46 |     date_max = date_max,\n##  47 |     granularity_geo = list(\n##  48 |       \"nodata\" = c(\n##  49 |         \"wardoslo\",\n##  50 |         \"extrawardoslo\",\n##  51 |         \"missingwardoslo\",\n##  52 |         \"wardbergen\",\n##  53 |         \"missingwardbergen\",\n##  54 |         \"wardstavanger\",\n##  55 |         \"missingwardstavanger\",\n##  56 |         \"notmainlandmunicip\",\n##  57 |         \"missingmunicip\",\n##  58 |         \"notmainlandcounty\",\n##  59 |         \"missingcounty\"\n##  60 |       ),\n##  61 |       \"municip\" = c(\n##  62 |         \"municip\"\n##  63 |       )\n##  64 |     )\n##  65 |   )\n##  66 | \n##  67 |   # Merge in the information you have at different geographical granularities\n##  68 |   # one level at a time\n##  69 |   # municip\n##  70 |   multiskeleton_day$municip[\n##  71 |     d_agg$day_municip,\n##  72 |     on = c(\"location_code\", \"date\"),\n##  73 |     c(\n##  74 |       \"temp_max\",\n##  75 |       \"temp_min\",\n##  76 |       \"precip\"\n##  77 |     ) := .(\n##  78 |       temp_max,\n##  79 |       temp_min,\n##  80 |       precip\n##  81 |     )\n##  82 |   ]\n##  83 | \n##  84 |   multiskeleton_day$municip[]\n##  85 | \n##  86 |   # Aggregate up to higher geographical granularities (county)\n##  87 |   multiskeleton_day$county <- multiskeleton_day$municip[\n##  88 |     fhidata::norway_locations_hierarchy(\n##  89 |       from = \"municip\",\n##  90 |       to = \"county\"\n##  91 |     ),\n##  92 |     on = c(\n##  93 |       \"location_code==from_code\"\n##  94 |     )\n##  95 |   ][,\n##  96 |     .(\n##  97 |       temp_max = mean(temp_max, na.rm = T),\n##  98 |       temp_min = mean(temp_min, na.rm = T),\n##  99 |       precip = mean(precip, na.rm = T),\n## 100 |       granularity_geo = \"county\"\n## 101 |     ),\n## 102 |     by = .(\n## 103 |       granularity_time,\n## 104 |       date,\n## 105 |       location_code = to_code\n## 106 |     )\n## 107 |   ]\n## 108 | \n## 109 |   multiskeleton_day$county[]\n## 110 | \n## 111 |   # Aggregate up to higher geographical granularities (nation)\n## 112 |   multiskeleton_day$nation <- multiskeleton_day$municip[\n## 113 |     ,\n## 114 |     .(\n## 115 |       temp_max = mean(temp_max, na.rm = T),\n## 116 |       temp_min = mean(temp_min, na.rm = T),\n## 117 |       precip = mean(precip, na.rm = T),\n## 118 |       granularity_geo = \"nation\",\n## 119 |       location_code = \"norge\"\n## 120 |     ),\n## 121 |     by = .(\n## 122 |       granularity_time,\n## 123 |       date\n## 124 |     )\n## 125 |   ]\n## 126 | \n## 127 |   multiskeleton_day$nation[]\n## 128 | \n## 129 |   # combine all the different granularity_geos\n## 130 |   skeleton_day <- rbindlist(multiskeleton_day, fill = TRUE, use.names = TRUE)\n## 131 | \n## 132 |   skeleton_day[]\n## 133 | \n## 134 |   # 10. (If desirable) aggregate up to higher time granularities\n## 135 |   # if necessary, it is now easy to aggregate up to weekly data from here\n## 136 |   skeleton_isoweek <- copy(skeleton_day)\n## 137 |   skeleton_isoweek[, isoyearweek := fhiplot::isoyearweek_c(date)]\n## 138 |   skeleton_isoweek <- skeleton_isoweek[\n## 139 |     ,\n## 140 |     .(\n## 141 |       temp_max = mean(temp_max, na.rm = T),\n## 142 |       temp_min = mean(temp_min, na.rm = T),\n## 143 |       precip = mean(precip, na.rm = T),\n## 144 |       granularity_time = \"isoweek\"\n## 145 |     ),\n## 146 |     keyby = .(\n## 147 |       isoyearweek,\n## 148 |       granularity_geo,\n## 149 |       location_code\n## 150 |     )\n## 151 |   ]\n## 152 | \n## 153 |   skeleton_isoweek[]\n## 154 | \n## 155 |   # we now need to format it and fill in missing structural variables\n## 156 |   # day\n## 157 |   skeleton_day[, sex := \"total\"]\n## 158 |   skeleton_day[, age := \"total\"]\n## 159 |   sc::fill_in_missing_v8(skeleton_day, border = config$border)\n## 160 | \n## 161 |   # isoweek\n## 162 |   skeleton_isoweek[, sex := \"total\"]\n## 163 |   skeleton_isoweek[, age := \"total\"]\n## 164 |   sc::fill_in_missing_v8(skeleton_isoweek, border = config$border)\n## 165 |   skeleton_isoweek[, date := as.Date(date)]\n## 166 | \n## 167 |   skeleton <- rbindlist(\n## 168 |     list(\n## 169 |       skeleton_day,\n## 170 |       skeleton_isoweek\n## 171 |     ),\n## 172 |     use.names = T\n## 173 |   )\n## 174 | \n## 175 |   # put data in db table\n## 176 |   schema$anon_example_weather_data$drop_all_rows_and_then_insert_data(skeleton)\n## 177 | \n## 178 |   # special case that runs after everything\n## 179 |   if (argset$last_analysis == TRUE) {\n## 180 | \n## 181 |   }\n## 182 | }\n## 183 | \n## 184 | # **** data_selector **** ----\n## 185 | #' weather_clean_data (data selector)\n## 186 | #' @param argset Argset\n## 187 | #' @param schema DB Schema\n## 188 | #' @export\n## 189 | weather_clean_data_data_selector <- function(argset, schema) {\n## 190 |   if (plnr::is_run_directly()) {\n## 191 |     # sc::tm_get_plans_argsets_as_dt(\"weather_clean_data\")\n## 192 | \n## 193 |     index_plan <- 1\n## 194 | \n## 195 |     argset <- sc::tm_get_argset(\"weather_clean_data\", index_plan = index_plan)\n## 196 |     schema <- sc::tm_get_schema(\"weather_clean_data\")\n## 197 |   }\n## 198 | \n## 199 |   # The database schemas can be accessed here\n## 200 |   d <- schema$anon_example_weather_rawdata$tbl() %>%\n## 201 |     sc::mandatory_db_filter(\n## 202 |       granularity_time = \"day\",\n## 203 |       granularity_time_not = NULL,\n## 204 |       granularity_geo = \"municip\",\n## 205 |       granularity_geo_not = NULL,\n## 206 |       country_iso3 = NULL,\n## 207 |       location_code = NULL,\n## 208 |       age = \"total\",\n## 209 |       age_not = NULL,\n## 210 |       sex = \"total\",\n## 211 |       sex_not = NULL\n## 212 |     ) %>%\n## 213 |     dplyr::select(\n## 214 |       granularity_time,\n## 215 |       # granularity_geo,\n## 216 |       # country_iso3,\n## 217 |       location_code,\n## 218 |       # border,\n## 219 |       # age,\n## 220 |       # sex,\n## 221 | \n## 222 |       date,\n## 223 | \n## 224 |       # isoyear,\n## 225 |       # isoweek,\n## 226 |       # isoyearweek,\n## 227 |       # season,\n## 228 |       # seasonweek,\n## 229 | \n## 230 |       # calyear,\n## 231 |       # calmonth,\n## 232 |       # calyearmonth,\n## 233 | \n## 234 |       temp_max,\n## 235 |       temp_min,\n## 236 |       precip\n## 237 |     ) %>%\n## 238 |     dplyr::collect() %>%\n## 239 |     as.data.table() %>%\n## 240 |     setorder(\n## 241 |       location_code,\n## 242 |       date\n## 243 |     )\n## 244 | \n## 245 |   # The variable returned must be a named list\n## 246 |   retval <- list(\n## 247 |     \"day_municip\" = d\n## 248 |   )\n## 249 | \n## 250 |   retval\n## 251 | }\n## 252 | \n## 253 | # **** functions **** ----"},{"path":"file-layout.html","id":"weather_export_weather_plots.r","chapter":"3 File Layout","heading":"3.12.3 weather_export_weather_plots.r","text":"https://github.com/sykdomspulsen-org/scskeleton/blob/main/R/weather_export_plots.r","code":"## https://github.com/sykdomspulsen-org/scskeleton/blob/main/R/weather_export_plots.r\n## \n##   1 | # **** action **** ----\n##   2 | #' weather_export_plots (action)\n##   3 | #' @param data Data\n##   4 | #' @param argset Argset\n##   5 | #' @param schema DB Schema\n##   6 | #' @export\n##   7 | weather_export_plots_action <- function(data, argset, schema) {\n##   8 |   # tm_run_task(\"weather_export_plots\")\n##   9 | \n##  10 |   if(plnr::is_run_directly()){\n##  11 |     # sc::tm_get_plans_argsets_as_dt(\"weather_export_plots\")\n##  12 | \n##  13 |     index_plan <- 1\n##  14 |     index_analysis <- 1\n##  15 | \n##  16 |     data <- sc::tm_get_data(\"weather_export_plots\", index_plan = index_plan)\n##  17 |     argset <- sc::tm_get_argset(\"weather_export_plots\", index_plan = index_plan, index_analysis = index_analysis)\n##  18 |     schema <- sc::tm_get_schema(\"weather_export_plots\")\n##  19 |   }\n##  20 | \n##  21 |   # code goes here\n##  22 |   # special case that runs before everything\n##  23 |   if(argset$first_analysis == TRUE){\n##  24 | \n##  25 |   }\n##  26 | \n##  27 |   # create the output_dir (if it doesn't exist)\n##  28 |   fs::dir_create(glue::glue(argset$output_dir))\n##  29 | \n##  30 |   q <- ggplot(data$data, aes(x = date, ymin = temp_min, ymax = temp_max))\n##  31 |   q <- q + geom_ribbon(alpha = 0.5)\n##  32 | \n##  33 |   ggsave(\n##  34 |     filename = glue::glue(argset$output_absolute_path),\n##  35 |     plot = q\n##  36 |   )\n##  37 | \n##  38 |   # special case that runs after everything\n##  39 |   # copy to anon_web?\n##  40 |   if(argset$last_analysis == TRUE){\n##  41 | \n##  42 |   }\n##  43 | }\n##  44 | \n##  45 | # **** data_selector **** ----\n##  46 | #' weather_export_plots (data selector)\n##  47 | #' @param argset Argset\n##  48 | #' @param schema DB Schema\n##  49 | #' @export\n##  50 | weather_export_plots_data_selector = function(argset, schema){\n##  51 |   if(plnr::is_run_directly()){\n##  52 |     # sc::tm_get_plans_argsets_as_dt(\"weather_export_plots\")\n##  53 | \n##  54 |     index_plan <- 1\n##  55 | \n##  56 |     argset <- sc::tm_get_argset(\"weather_export_plots\", index_plan = index_plan)\n##  57 |     schema <- sc::tm_get_schema(\"weather_export_plots\")\n##  58 |   }\n##  59 | \n##  60 |   # The database schemas can be accessed here\n##  61 |   d <- schema$anon_example_weather_data$tbl() %>%\n##  62 |     sc::mandatory_db_filter(\n##  63 |       granularity_time = NULL,\n##  64 |       granularity_time_not = NULL,\n##  65 |       granularity_geo = NULL,\n##  66 |       granularity_geo_not = NULL,\n##  67 |       country_iso3 = NULL,\n##  68 |       location_code = argset$location_code,\n##  69 |       age = NULL,\n##  70 |       age_not = NULL,\n##  71 |       sex = NULL,\n##  72 |       sex_not = NULL\n##  73 |     ) %>%\n##  74 |     dplyr::select(\n##  75 |       # granularity_time,\n##  76 |       # granularity_geo,\n##  77 |       # country_iso3,\n##  78 |       # location_code,\n##  79 |       # border,\n##  80 |       # age,\n##  81 |       # sex,\n##  82 | \n##  83 |       date,\n##  84 | \n##  85 |       # isoyear,\n##  86 |       # isoweek,\n##  87 |       # isoyearweek,\n##  88 |       # season,\n##  89 |       # seasonweek,\n##  90 |       #\n##  91 |       # calyear,\n##  92 |       # calmonth,\n##  93 |       # calyearmonth,\n##  94 | \n##  95 |       temp_max,\n##  96 |       temp_min\n##  97 |     ) %>%\n##  98 |     dplyr::collect() %>%\n##  99 |     as.data.table() %>%\n## 100 |     setorder(\n## 101 |       # location_code,\n## 102 |       date\n## 103 |     )\n## 104 | \n## 105 |   # The variable returned must be a named list\n## 106 |   retval <- list(\n## 107 |     \"data\" = d\n## 108 |   )\n## 109 |   retval\n## 110 | }\n## 111 | \n## 112 | # **** functions **** ----\n## 113 | \n## 114 | \n## 115 | \n## 116 |"},{"path":"tutorial-1-introduction.html","id":"tutorial-1-introduction","chapter":"4 Tutorial 1: Introduction","heading":"4 Tutorial 1: Introduction","text":"","code":""},{"path":"tutorial-1-introduction.html","id":"setup","chapter":"4 Tutorial 1: Introduction","heading":"4.1 Setup","text":"Implementing Sykdomspulsen Core requires number functions called correct order. make simple possible, provided skeleton implementation sykdomspulsen-org/scskeletonFor tutorial clone GitHub repo server. package working throughout tutorial. may choose global find/replace sc-tutorial-start name want R package. refer R package “sc implementation”.can also clone sykdomspulsen-org/sc-tutorial-end server. end product tutorial, refer order check work.purposes tutorial, assume reader either using RStudio Server Open Source RStudio Workbench inside Docker containers built according Sykdomspulsen specifications. refer implementation RStudio Server Open Source/RStudio Workbench generic term “RStudio”.","code":""},{"path":"tutorial-1-introduction.html","id":"load-the-code","chapter":"4 Tutorial 1: Introduction","heading":"4.2 Load the code","text":"Opensc-tutorial-start RStudio project mode. Restart R session via Ctrl+Shift+F10, rstudioapi::restartSession(), Session > Restart R. ensure clean working environment begin. may now load sc implementation. can done via Ctrl+Shift+L, devtools::load_all(\".\"), Build > Load .wokring sykdomspulsen infrastructure might see warning message form: sh: 1: /bin/authenticate.sh: found. authentication beeing done automatically sign . worry purpose tutorial. might also see warnign starting “Objects listed exports, present namespace:”. can also ignored.can now see schemas loaded running sc::tm_get_schema_names(). schemas included skeleton. Note schemas beginning config_* special schemas automatically generated sc.see schemas related weather, income, houseprices might see Warning form “setup_ns_exports(path, export_all, export_imports) : Objects listed exports…..”. expected.can also see tasks loaded running sc::tm_get_task_names(). tasks included skeleton. yet made tasks, hence see NULL.","code":"\nrstudioapi::restartSession()\ndevtools::load_all(\".\")\nsc::tm_get_schema_names()\n## [1] \"config_last_updated\"                                           \"config_structure_time\"                                        \n## [3] \"rundate\"                                                       \"config_datetime\"                                              \n## [5] \"anon_example_weather_rawdata\"                                  \"anon_example_weather_data\"                                    \n## [7] \"anon_example_income\"                                           \"anon_example_house_prices\"                                    \n## [9] \"anon_example_house_prices_outliers_after_adjusting_for_income\"\nsc::tm_get_task_names()\n## [1] \"weather_download_and_import_rawdata\"                            \"weather_clean_data\"                                            \n## [3] \"weather_export_plots\"                                           \"household_incomes_and_house_prices_import_data\"                \n## [5] \"household_incomes_and_house_prices_fit_model_and_find_outliers\" \"household_incomes_and_house_prices_plot\""},{"path":"tutorial-1-introduction.html","id":"weather-data-example","chapter":"4 Tutorial 1: Introduction","heading":"4.3 Weather data example","text":"now going create weather data example. end goal plot minimum maximal temperature counties Norway. involves task downloading importing raw data. need specify schema describes data want store, data identifies unique rows access data. also need define task task definition, .e., task name, many cores want use, structure task, common arguments etc. Finally actually implement task writing data selector function, action function sometimes detailed function describing plans analyses task.also create task cleaning raw data, schema, task definition implementation data selector function action function.Finally create task creation plots.schemas spesified 03_db_schemas.r, task definitions specified 04_tasks.r. data selector functions action functions corresponding task respective script name specified task description.","code":""},{"path":"tutorial-1-introduction.html","id":"developing-weather_download_and_import_rawdata","chapter":"4 Tutorial 1: Introduction","heading":"4.4 Developing weather_download_and_import_rawdata","text":"walk development task downloads weather data API imports raw data database table.","code":""},{"path":"tutorial-1-introduction.html","id":"schemas","chapter":"4 Tutorial 1: Introduction","heading":"4.4.1 1. Schemas","text":"first step developing task specifying schemas used.strongly recommended use RStudio Addins menu help quickly insert code templates.go script 03_db_schemas.r can see function called set_db_schemas. schemas placed within function. scroll can see already schema called anon_example_weather_rawdata commented .now going recreate schema.\nMake sure pointer inside curly brackets. Go Addins menu click Insert db schema (anon). now created boiler plate schema.","code":"## https://github.com/sykdomspulsen-org/sc-tutorial-end/blob/main/R/03_db_schemas.r#L18-L64\n## \n## 18 |   ## > anon_example_weather_rawdata ----\n## 19 |   sc::add_schema_v8(\n## 20 |     name_access = c(\"anon\"),\n## 21 |     name_grouping = \"example_weather\",\n## 22 |     name_variant = \"rawdata\",\n## 23 |     db_configs = sc::config$db_configs,\n## 24 |     field_types =  c(\n## 25 |       \"granularity_time\" = \"TEXT\",\n## 26 |       \"granularity_geo\" = \"TEXT\",\n## 27 |       \"country_iso3\" = \"TEXT\",\n## 28 |       \"location_code\" = \"TEXT\",\n## 29 |       \"border\" = \"INTEGER\",\n## 30 |       \"age\" = \"TEXT\",\n## 31 |       \"sex\" = \"TEXT\",\n## 32 | \n## 33 |       \"date\" = \"DATE\",\n## 34 | \n## 35 |       \"isoyear\" = \"INTEGER\",\n## 36 |       \"isoweek\" = \"INTEGER\",\n## 37 |       \"isoyearweek\" = \"TEXT\",\n## 38 |       \"season\" = \"TEXT\",\n## 39 |       \"seasonweek\" = \"DOUBLE\",\n## 40 | \n## 41 |       \"calyear\" = \"INTEGER\",\n## 42 |       \"calmonth\" = \"INTEGER\",\n## 43 |       \"calyearmonth\" = \"TEXT\",\n## 44 | \n## 45 |       \"temp_max\" = \"DOUBLE\",\n## 46 |       \"temp_min\" = \"DOUBLE\",\n## 47 |       \"precip\" = \"DOUBLE\"\n## 48 |     ),\n## 49 |     keys = c(\n## 50 |       \"granularity_time\",\n## 51 |       \"location_code\",\n## 52 |       \"date\",\n## 53 |       \"age\",\n## 54 |       \"sex\"\n## 55 |     ),\n## 56 |     censors = list(\n## 57 |       anon = list(\n## 58 | \n## 59 |       )\n## 60 |     ),\n## 61 |     validator_field_types = sc::validator_field_types_sykdomspulsen,\n## 62 |     validator_field_contents = sc::validator_field_contents_sykdomspulsen,\n## 63 |     info = \"This db table is used for...\"\n## 64 |   )"},{"path":"tutorial-1-introduction.html","id":"schema-name","chapter":"4 Tutorial 1: Introduction","heading":"4.4.1.1 Schema name","text":"Start replacing GROUPING_VARIANT anon_GROUPING_VARIANT name schema. example example_weather_rawdata. grouping now example_weather variant rawdata.Fill inn name_grouping name_variant. name schema anon_example_weather_rawdata.example define name schema anon_example_weather_weather_rawdata.","code":"## https://github.com/sykdomspulsen-org/sc-tutorial-end/blob/main/R/03_db_schemas.r#L20-L22\n## \n## 20 |     name_access = c(\"anon\"),\n## 21 |     name_grouping = \"example_weather\",\n## 22 |     name_variant = \"rawdata\","},{"path":"tutorial-1-introduction.html","id":"validators","chapter":"4 Tutorial 1: Introduction","heading":"4.4.1.2 Validators","text":"validators pre-made change anything.validators check:column names/field types schema definition line style guidelines?values/field contents datasets uploaded database correct? E.g. date column actually contain dates?using validator_field_types = sc::validator_field_types_sykdomspulsen expect first 16 columns always follows (.e. standardized structural data):field info contain short description data table.","code":"## https://github.com/sykdomspulsen-org/sc-tutorial-end/blob/main/R/03_db_schemas.r#L61-L63\n## \n## 61 |     validator_field_types = sc::validator_field_types_sykdomspulsen,\n## 62 |     validator_field_contents = sc::validator_field_contents_sykdomspulsen,\n## 63 |     info = \"This db table is used for...\"## https://github.com/sykdomspulsen-org/sc-tutorial-end/blob/main/R/03_db_schemas.r#L25-L43\n## \n## 25 |       \"granularity_time\" = \"TEXT\",\n## 26 |       \"granularity_geo\" = \"TEXT\",\n## 27 |       \"country_iso3\" = \"TEXT\",\n## 28 |       \"location_code\" = \"TEXT\",\n## 29 |       \"border\" = \"INTEGER\",\n## 30 |       \"age\" = \"TEXT\",\n## 31 |       \"sex\" = \"TEXT\",\n## 32 | \n## 33 |       \"date\" = \"DATE\",\n## 34 | \n## 35 |       \"isoyear\" = \"INTEGER\",\n## 36 |       \"isoweek\" = \"INTEGER\",\n## 37 |       \"isoyearweek\" = \"TEXT\",\n## 38 |       \"season\" = \"TEXT\",\n## 39 |       \"seasonweek\" = \"DOUBLE\",\n## 40 | \n## 41 |       \"calyear\" = \"INTEGER\",\n## 42 |       \"calmonth\" = \"INTEGER\",\n## 43 |       \"calyearmonth\" = \"TEXT\","},{"path":"tutorial-1-introduction.html","id":"field-typescolumn-names","chapter":"4 Tutorial 1: Introduction","heading":"4.4.1.3 Field types/column names","text":"Add spesific column names types needed. case want store maximum minimum temperature precipitation. Call “temp_max”, “temp_min”, “precip”. “DOUBLE”. Remove \"XXXX_n\" = \"INTEGER\", \"XXXX_pr\" = \"DOUBLE\"dummy variables.extra columns contain context-specific data dataset.","code":"## https://github.com/sykdomspulsen-org/sc-tutorial-end/blob/main/R/03_db_schemas.r#L45-L47\n## \n## 45 |       \"temp_max\" = \"DOUBLE\",\n## 46 |       \"temp_min\" = \"DOUBLE\",\n## 47 |       \"precip\" = \"DOUBLE\""},{"path":"tutorial-1-introduction.html","id":"keys-1","chapter":"4 Tutorial 1: Introduction","heading":"4.4.1.4 Keys","text":"combination columns represents unique row dataset. dataset combination “granularity_geo”, “location_code”, “date”, “age”, “sex” initial suggestions sufficient.","code":"## https://github.com/sykdomspulsen-org/sc-tutorial-end/blob/main/R/03_db_schemas.r#L49-L55\n## \n## 49 |     keys = c(\n## 50 |       \"granularity_time\",\n## 51 |       \"location_code\",\n## 52 |       \"date\",\n## 53 |       \"age\",\n## 54 |       \"sex\"\n## 55 |     ),"},{"path":"tutorial-1-introduction.html","id":"censoring","chapter":"4 Tutorial 1: Introduction","heading":"4.4.1.5 Censoring","text":"Censoring applied datasets. example apply censoring hence remove boiler plate suggestions.","code":"## https://github.com/sykdomspulsen-org/sc-tutorial-end/blob/main/R/03_db_schemas.r#L56-L60\n## \n## 56 |     censors = list(\n## 57 |       anon = list(\n## 58 | \n## 59 |       )\n## 60 |     ),"},{"path":"tutorial-1-introduction.html","id":"task-definition-task_from_config","chapter":"4 Tutorial 1: Introduction","heading":"4.4.2 2. Task definition (task_from_config)","text":"Now schema. second step defining task.strongly recommended use RStudio Addins menu help quickly insert code templates.Go script 04_tasks.r place curser inside curly bracket. Use addins menu click Insert task_from_config.Now boilerplate task definition.","code":"## https://github.com/sykdomspulsen-org/sc-tutorial-end/blob/main/R/04_tasks.r#L21-L43\n## \n## 21 |   sc::add_task_from_config_v8(\n## 22 |     name_grouping = \"weather\",\n## 23 |     name_action = \"download_and_import_rawdata\",\n## 24 |     name_variant = NULL,\n## 25 |     cores = 1,\n## 26 |     plan_analysis_fn_name = NULL,\n## 27 |     for_each_plan = plnr::expand_list(\n## 28 |       location_code = fhidata::norway_locations_names()[granularity_geo %in% c(\"municip\")]$location_code\n## 29 |     ),\n## 30 |     for_each_analysis = NULL,\n## 31 |     universal_argset = NULL,\n## 32 |     upsert_at_end_of_each_plan = FALSE,\n## 33 |     insert_at_end_of_each_plan = FALSE,\n## 34 |     action_fn_name = \"scexample::weather_download_and_import_rawdata_action\",\n## 35 |     data_selector_fn_name = \"scexample::weather_download_and_import_rawdata_data_selector\",\n## 36 |     schema = list(\n## 37 |       # input\n## 38 | \n## 39 |       # output\n## 40 |       \"anon_example_weather_rawdata\" = sc::config$schemas$anon_example_weather_rawdata\n## 41 |     ),\n## 42 |     info = \"This task downloads and imports the raw weather data from MET's API at the municipal level\"\n## 43 |   )"},{"path":"tutorial-1-introduction.html","id":"task-name","chapter":"4 Tutorial 1: Introduction","heading":"4.4.2.1 Task name","text":"Replace TASK_NAME task name. example weather_download_and_import_rawdata. weather task/grouping download_and_import_rawdatais action name. Insert name_grouping, name_action. name_variant use NULL.Now name task defined weather_download_and_import_rawdata.","code":"## https://github.com/sykdomspulsen-org/sc-tutorial-end/blob/main/R/04_tasks.r#L22-L24\n## \n## 22 |     name_grouping = \"weather\",\n## 23 |     name_action = \"download_and_import_rawdata\",\n## 24 |     name_variant = NULL,"},{"path":"tutorial-1-introduction.html","id":"cpu-cores","chapter":"4 Tutorial 1: Introduction","heading":"4.4.2.2 CPU cores","text":"specify plans run sequentially 1 CPU core. number CPU cores 2 higher first last plans run sequentially, plans middle run parallel. first last plans always run sequentially allows us write “special” code first last plans (.e. “everything runs” “everything runs”).","code":"## https://github.com/sykdomspulsen-org/sc-tutorial-end/blob/main/R/04_tasks.r#L25-L25\n## \n## 25 |     cores = 1,"},{"path":"tutorial-1-introduction.html","id":"plananalysis-structure","chapter":"4 Tutorial 1: Introduction","heading":"4.4.2.3 Plan/analysis structure","text":"specify plan/analysis structure . may use one following combinations:plan_analysis_fn_name (rarely used)for_each_plan (plan-heavy, one analysis per plan)for_each_plan + for_each_analysis (typically analysis-heavy)plan_analysis_fn_name (rarely used) function provide list containing plan/analysis structure. generally used plan/analysis structure needs reactive depending upon external data (e.g. “unknown number data files provided day need cleaned”).for_each_plan list, element corresponding plan defined named list. Within named list, named elements translated argset elements available respective plans. particular for_each_plan defines task 356 plans (one municipality).for_each_analysis nearly for_each_plan. specifies kind analyses like perform within plan. named list, element corresponding analysis defined named list. Within named list, named elements translated argset elements available respective analyses.example for_each_plan correspond 11 tasks (one county):fhidata::norway_locations_names() gives us location codes Norway (try run console). Implement plan task location codes municipalities (municip) Norway.","code":"## https://github.com/sykdomspulsen-org/sc-tutorial-end/blob/main/R/04_tasks.r#L26-L30\n## \n## 26 |     plan_analysis_fn_name = NULL,\n## 27 |     for_each_plan = plnr::expand_list(\n## 28 |       location_code = fhidata::norway_locations_names()[granularity_geo %in% c(\"municip\")]$location_code\n## 29 |     ),\n## 30 |     for_each_analysis = NULL,\noptions(width = 150)\nfor_each_plan = plnr::expand_list(\n  location_code = fhidata::norway_locations_names()[granularity_geo %in% c(\"county\")]$location_code\n)\nfor_each_plan\n## [[1]]\n## [[1]]$location_code\n## [1] \"county42\"\n## \n## \n## [[2]]\n## [[2]]$location_code\n## [1] \"county34\"\n## \n## \n## [[3]]\n## [[3]]$location_code\n## [1] \"county15\"\n## \n## \n## [[4]]\n## [[4]]$location_code\n## [1] \"county18\"\n## \n## \n## [[5]]\n## [[5]]$location_code\n## [1] \"county03\"\n## \n## \n## [[6]]\n## [[6]]$location_code\n## [1] \"county11\"\n## \n## \n## [[7]]\n## [[7]]$location_code\n## [1] \"county54\"\n## \n## \n## [[8]]\n## [[8]]$location_code\n## [1] \"county50\"\n## \n## \n## [[9]]\n## [[9]]$location_code\n## [1] \"county38\"\n## \n## \n## [[10]]\n## [[10]]$location_code\n## [1] \"county46\"\n## \n## \n## [[11]]\n## [[11]]$location_code\n## [1] \"county30\""},{"path":"tutorial-1-introduction.html","id":"universal-argset","chapter":"4 Tutorial 1: Introduction","heading":"4.4.3 Universal argset","text":"can specify named list, named elements translated argset elements available plans/analyses.","code":"## https://github.com/sykdomspulsen-org/sc-tutorial-end/blob/main/R/04_tasks.r#L31-L31\n## \n## 31 |     universal_argset = NULL,"},{"path":"tutorial-1-introduction.html","id":"upsertinsert-at-end-of-each-plan","chapter":"4 Tutorial 1: Introduction","heading":"4.4.3.1 Upsert/insert at end of each plan","text":"include schema called output, options let upsert/insert returned value action_fn_name end plan. important nuance, write/develop task, can (typically) write one function (action_fn_name) applied analyses. means action_fn wants upsert/insert data schema, (typically) within every analysis. analysis-heavy task, lot frequent traffic databases, may affect performance. using flags, can restrict upsert/insert end plan, may increase performance.","code":"## https://github.com/sykdomspulsen-org/sc-tutorial-end/blob/main/R/04_tasks.r#L32-L33\n## \n## 32 |     upsert_at_end_of_each_plan = FALSE,\n## 33 |     insert_at_end_of_each_plan = FALSE,"},{"path":"tutorial-1-introduction.html","id":"action_fn_name-1","chapter":"4 Tutorial 1: Introduction","heading":"4.4.3.2 action_fn_name","text":"action_fn_name specifies name function corresponds action. , function called every analysis. Note :stringIt must include package nameIt typically form PACKAGE::TASK_actionIn case package scskeleton TASK weather_download_and_import_rawdata. Insert task.","code":"## https://github.com/sykdomspulsen-org/sc-tutorial-end/blob/main/R/04_tasks.r#L34-L34\n## \n## 34 |     action_fn_name = \"scexample::weather_download_and_import_rawdata_action\","},{"path":"tutorial-1-introduction.html","id":"data_selector_fn_name-1","chapter":"4 Tutorial 1: Introduction","heading":"4.4.3.3 data_selector_fn_name","text":"data_selecotr_fn_name specifies name function corresponds data selector. , function called start every plan provide data analyses inside plan. Note :stringIt must include package nameIt typically form PACKAGE::TASK_data_selectorTry guess example.","code":"## https://github.com/sykdomspulsen-org/sc-tutorial-end/blob/main/R/04_tasks.r#L35-L35\n## \n## 35 |     data_selector_fn_name = \"scexample::weather_download_and_import_rawdata_data_selector\","},{"path":"tutorial-1-introduction.html","id":"schemas-1","chapter":"4 Tutorial 1: Introduction","heading":"4.4.3.4 Schemas","text":"schemas specify named list, element consists schema. names passed schema$name action_fn_name data_selector_fn_name. must include schemas get data schemas store data .example yet data specify schema earlier called anon_example_weather_rawdata. meand can remove boiler plate input schema replace SCHEMA_NAME_2 anon_example_weather_rawdata.","code":"## https://github.com/sykdomspulsen-org/sc-tutorial-end/blob/main/R/04_tasks.r#L36-L41\n## \n## 36 |     schema = list(\n## 37 |       # input\n## 38 | \n## 39 |       # output\n## 40 |       \"anon_example_weather_rawdata\" = sc::config$schemas$anon_example_weather_rawdata\n## 41 |     ),"},{"path":"tutorial-1-introduction.html","id":"task-description","chapter":"4 Tutorial 1: Introduction","heading":"4.4.3.5 Task description","text":"Finally create small task description.","code":""},{"path":"tutorial-1-introduction.html","id":"data_selector_fn-1","chapter":"4 Tutorial 1: Introduction","heading":"4.4.4 3. data_selector_fn","text":"third step creating task defining data selector function. function perform “one data-pull per plan” subsequently provide data action.Go script weather_download_and_import_rawdata.r.Use RStudio Addins menu help quickly insert code templates clicking Insert action data selector.Just like , pre-made boilerplate ready go! Find data_selector part script replace TASK_NAME task name weather_download_and_import_rawdata.","code":""},{"path":"tutorial-1-introduction.html","id":"plnris_run_directly","chapter":"4 Tutorial 1: Introduction","heading":"4.4.4.1 plnr::is_run_directly()","text":"top data_selector_fns see section code wrapped inside (plnr::is_run_directly()) {. code run manually highlighted inside RStudio “run”. extremely beneficial user, means user can easily write small pieces code used development, run code run “properly”.Sykdomspulsen core uses sections let user “jump” directly function. Look arguments weather_download_and_import_rawdata_data_selector see needs argset schema.code inside (plnr::is_run_directly()) { loads argset schema index_plan = 1. running lines, can treat inside weather_download_and_import_rawdata_data_selector interactive script!makes development code extremely easy “everything interactive script”.Check argset schema running lines within (plnr::is_run_directly()) {}.","code":"## https://github.com/sykdomspulsen-org/sc-tutorial-end/blob/main/R/weather_download_and_import_rawdata.r#L94-L101\n## \n##  94 |   if (plnr::is_run_directly()) {\n##  95 |     # sc::tm_get_plans_argsets_as_dt(\"weather_download_and_import_rawdata\")\n##  96 | \n##  97 |     index_plan <- 1\n##  98 | \n##  99 |     argset <- sc::tm_get_argset(\"weather_download_and_import_rawdata\", index_plan = index_plan)\n## 100 |     schema <- sc::tm_get_schema(\"weather_download_and_import_rawdata\")\n## 101 |   }"},{"path":"tutorial-1-introduction.html","id":"getting-data","chapter":"4 Tutorial 1: Introduction","heading":"4.4.5 Getting data","text":"majority data_selector_fn concerned selecting data (obviously). Remember data selected meet needs plan. 11 plans (one county), data_selector_fn extract data county interest.Take look argset plan = 1.\nSince input data schema can remove premade schema. Instead going get data fhimaps::norway_lau2_map_b2020_default_dt provides latitudes (lat) longitudes (long). Explore available data running fhimaps::norway_lau2_map_b2020_default_dt console. returns data table. want mean latitude longitude specific location_code particular plan analysis. Therefor try select data call gps.Now download weather forcast specific location api using httr::GET glue::glue get right address.httr::GET(glue::glue(“https://api.met./weatherapi/locationforecast/2.0/classic?lat={gps$lat}&lon={gps$long}”), httr::content_type_xml()).\nUse xml2::read_xml() read content. Take peak implement .","code":"## https://github.com/sykdomspulsen-org/sc-tutorial-end/blob/main/R/weather_download_and_import_rawdata.r#L103-L111\n## \n## 103 |   # find the mid lat/long for the specified location_code\n## 104 |   gps <- fhimaps::norway_lau2_map_b2020_default_dt[location_code == argset$location_code,.(\n## 105 |     lat = mean(lat),\n## 106 |     long = mean(long)\n## 107 |   )]\n## 108 | \n## 109 |   # download the forecast for the specified location_code\n## 110 |   d <- httr::GET(glue::glue(\"https://api.met.no/weatherapi/locationforecast/2.0/classic?lat={gps$lat}&lon={gps$long}\"), httr::content_type_xml())\n## 111 |   d <- xml2::read_xml(d$content)"},{"path":"tutorial-1-introduction.html","id":"returning-data","chapter":"4 Tutorial 1: Introduction","heading":"4.4.6 Returning data","text":"data_selector_fn needs return named list. made available user action_fn (weather_download_and_import_rawdata_action) via argument data.task replace “NAME” name data example “data”.entire data selector function now look like .Check data selector function works restarting R (ctrl + shift + F10) loading packages (ctrl + shift + L) running data selector function line line.","code":"## https://github.com/sykdomspulsen-org/sc-tutorial-end/blob/main/R/weather_download_and_import_rawdata.r#L113-L116\n## \n## 113 |   # The variable returned must be a named list\n## 114 |   retval <- list(\n## 115 |     \"data\" = d\n## 116 |   )## https://github.com/sykdomspulsen-org/sc-tutorial-end/blob/main/R/weather_download_and_import_rawdata.r#L88-L119\n## \n##  88 | # **** data_selector **** ----\n##  89 | #' weather_download_and_import_rawdata (data selector)\n##  90 | #' @param argset Argset\n##  91 | #' @param schema DB Schema\n##  92 | #' @export\n##  93 | weather_download_and_import_rawdata_data_selector <- function(argset, schema) {\n##  94 |   if (plnr::is_run_directly()) {\n##  95 |     # sc::tm_get_plans_argsets_as_dt(\"weather_download_and_import_rawdata\")\n##  96 | \n##  97 |     index_plan <- 1\n##  98 | \n##  99 |     argset <- sc::tm_get_argset(\"weather_download_and_import_rawdata\", index_plan = index_plan)\n## 100 |     schema <- sc::tm_get_schema(\"weather_download_and_import_rawdata\")\n## 101 |   }\n## 102 | \n## 103 |   # find the mid lat/long for the specified location_code\n## 104 |   gps <- fhimaps::norway_lau2_map_b2020_default_dt[location_code == argset$location_code,.(\n## 105 |     lat = mean(lat),\n## 106 |     long = mean(long)\n## 107 |   )]\n## 108 | \n## 109 |   # download the forecast for the specified location_code\n## 110 |   d <- httr::GET(glue::glue(\"https://api.met.no/weatherapi/locationforecast/2.0/classic?lat={gps$lat}&lon={gps$long}\"), httr::content_type_xml())\n## 111 |   d <- xml2::read_xml(d$content)\n## 112 | \n## 113 |   # The variable returned must be a named list\n## 114 |   retval <- list(\n## 115 |     \"data\" = d\n## 116 |   )\n## 117 | \n## 118 |   retval\n## 119 | }"},{"path":"tutorial-1-introduction.html","id":"action_fn-1","chapter":"4 Tutorial 1: Introduction","heading":"4.4.7 4. action_fn","text":"fourth step defining action function. function perform “action” within analysis. , given:dataargsetschemaWhat actually want ? Find action part script replace TASK_NAME task name weather_download_and_import_rawdata.","code":""},{"path":"tutorial-1-introduction.html","id":"plnris_run_directly-1","chapter":"4 Tutorial 1: Introduction","heading":"4.4.7.1 plnr::is_run_directly()","text":"top action_fns see section code wrapped inside (plnr::is_run_directly()) {. works exactly data_selector_fn.Look arguments weather_download_and_import_rawdata_data_selector see needs data, argset schema. code inside (plnr::is_run_directly()) { loads data, argset schema index_plan = 1 index_analysis = 1. running lines, can treat inside weather_download_and_import_rawdata_action interactive script!Check data, argset schema running lines.","code":"## https://github.com/sykdomspulsen-org/sc-tutorial-end/blob/main/R/weather_download_and_import_rawdata.r#L95-L102\n## \n##  95 |     # sc::tm_get_plans_argsets_as_dt(\"weather_download_and_import_rawdata\")\n##  96 | \n##  97 |     index_plan <- 1\n##  98 | \n##  99 |     argset <- sc::tm_get_argset(\"weather_download_and_import_rawdata\", index_plan = index_plan)\n## 100 |     schema <- sc::tm_get_schema(\"weather_download_and_import_rawdata\")\n## 101 |   }\n## 102 |"},{"path":"tutorial-1-introduction.html","id":"argsetfirst_analysis","chapter":"4 Tutorial 1: Introduction","heading":"4.4.7.2 argset$first_analysis","text":"code run first analysis. typically used drop rows database, following code may insert data (faster) instead using upsert data (slower). ran full task beginning tutorial can insert schema$anon_example_weather_rawdata$drop_all_rows() inside delete stored data.","code":"## https://github.com/sykdomspulsen-org/sc-tutorial-end/blob/main/R/weather_download_and_import_rawdata.r#L21-L24\n## \n## 21 |   # special case that runs before everything\n## 22 |   if (argset$first_analysis == TRUE) {\n## 23 | \n## 24 |   }"},{"path":"tutorial-1-introduction.html","id":"doing-things","chapter":"4 Tutorial 1: Introduction","heading":"4.4.7.3 Doing things","text":"tutorial go much detail data collected now copy content action function action function. (find commented file.)Every analysis perform code.Run line line pay special attention data data_selector_fn accesed, last part data formatted use sc::fill_in_missing_v8(res, border = 2020) fill inn mandatory data columns end data inserted database.","code":"## https://github.com/sykdomspulsen-org/sc-tutorial-end/blob/main/R/weather_download_and_import_rawdata.r#L26-L80\n## \n## 26 |   a <- data$data\n## 27 | \n## 28 |   baz <- xml2::xml_find_all(a, \".//maxTemperature\")\n## 29 |   res <- vector(\"list\", length = length(baz))\n## 30 |   for (i in seq_along(baz)) {\n## 31 |     parent <- xml2::xml_parent(baz[[i]])\n## 32 |     grandparent <- xml2::xml_parent(parent)\n## 33 |     time_from <- xml2::xml_attr(grandparent, \"from\")\n## 34 |     time_to <- xml2::xml_attr(grandparent, \"to\")\n## 35 |     x <- xml2::xml_find_all(parent, \".//minTemperature\")\n## 36 |     temp_min <- xml2::xml_attr(x, \"value\")\n## 37 |     x <- xml2::xml_find_all(parent, \".//maxTemperature\")\n## 38 |     temp_max <- xml2::xml_attr(x, \"value\")\n## 39 |     x <- xml2::xml_find_all(parent, \".//precipitation\")\n## 40 |     precip <- xml2::xml_attr(x, \"value\")\n## 41 |     res[[i]] <- data.frame(\n## 42 |       time_from = as.character(time_from),\n## 43 |       time_to = as.character(time_to),\n## 44 |       temp_max = as.numeric(temp_max),\n## 45 |       temp_min = as.numeric(temp_min),\n## 46 |       precip = as.numeric(precip)\n## 47 |     )\n## 48 |   }\n## 49 |   res <- rbindlist(res)\n## 50 |   res <- res[stringr::str_sub(time_from, 12, 13) %in% c(\"00\", \"06\", \"12\", \"18\")]\n## 51 |   res[, date := as.Date(stringr::str_sub(time_from, 1, 10))]\n## 52 |   res[, N := .N, by = date]\n## 53 |   res <- res[N == 4]\n## 54 |   res <- res[\n## 55 |     ,\n## 56 |     .(\n## 57 |       temp_max = max(temp_max),\n## 58 |       temp_min = min(temp_min),\n## 59 |       precip = sum(precip)\n## 60 |     ),\n## 61 |     keyby = .(date)\n## 62 |   ]\n## 63 | \n## 64 |   # we look at the downloaded data\n## 65 |   # res\n## 66 | \n## 67 |   # we now need to format it\n## 68 |   res[, granularity_time := \"day\"]\n## 69 |   res[, sex := \"total\"]\n## 70 |   res[, age := \"total\"]\n## 71 |   res[, location_code := argset$location_code]\n## 72 | \n## 73 |   # fill in missing structural variables\n## 74 |   sc::fill_in_missing_v8(res, border = 2020)\n## 75 | \n## 76 |   # we look at the downloaded data\n## 77 |   # res\n## 78 | \n## 79 |   # put data in db table\n## 80 |   schema$anon_example_weather_rawdata$insert_data(res)"},{"path":"tutorial-1-introduction.html","id":"accessing-data-from-data_selector_fn","chapter":"4 Tutorial 1: Introduction","heading":"4.4.7.4 Accessing data from data_selector_fn","text":"see access data passed us data_selector_fn","code":"## https://github.com/sykdomspulsen-org/sc-tutorial-end/blob/main/R/weather_download_and_import_rawdata.r#L26-L26\n## \n## 26 |   a <- data$data"},{"path":"tutorial-1-introduction.html","id":"structural-datascfill_in_missing_v8","chapter":"4 Tutorial 1: Introduction","heading":"4.4.7.5 Structural data/sc::fill_in_missing_v8","text":"16 structural data columns expect. columns typically lot redundancy (e.g. date, isoyear, isoyearweek). make things easier, provide function called sc::fill_in_missing_v8 uses information present dataset try impute missing structural data.","code":"## https://github.com/sykdomspulsen-org/sc-tutorial-end/blob/main/R/weather_download_and_import_rawdata.r#L68-L74\n## \n## 68 |   res[, granularity_time := \"day\"]\n## 69 |   res[, sex := \"total\"]\n## 70 |   res[, age := \"total\"]\n## 71 |   res[, location_code := argset$location_code]\n## 72 | \n## 73 |   # fill in missing structural variables\n## 74 |   sc::fill_in_missing_v8(res, border = 2020)"},{"path":"tutorial-1-introduction.html","id":"insertupsert-to-databases","chapter":"4 Tutorial 1: Introduction","heading":"4.4.7.6 Insert/upsert to databases","text":"insert data database table.Insert append (data already exist database table), upsert “update (overwrite) already exists, insert (append) doesn’t”.want deleate data use schema$NAME_DATABASE$drop_all_rows() case schema$anon_example_weather_rawdata$drop_all_rows().","code":"## https://github.com/sykdomspulsen-org/sc-tutorial-end/blob/main/R/weather_download_and_import_rawdata.r#L80-L80\n## \n## 80 |   schema$anon_example_weather_rawdata$insert_data(res)"},{"path":"tutorial-1-introduction.html","id":"argsetlast_analysis","chapter":"4 Tutorial 1: Introduction","heading":"4.4.7.7 argset$last_analysis","text":"code run last analysis. typically used copy internal database table (.e. one public directly viewing) external database (.e. one public directly viewing).distinguishing internal database tables (e.g. anon_webkhtint_test) external database tables (e.g. anon_webkht_test) can whatever want anon_webkhtint_test anon_webkht_test remains place untouched. makes less likely mistakes affect APIs websites public uses.","code":"## https://github.com/sykdomspulsen-org/sc-tutorial-end/blob/main/R/weather_download_and_import_rawdata.r#L21-L24\n## \n## 21 |   # special case that runs before everything\n## 22 |   if (argset$first_analysis == TRUE) {\n## 23 | \n## 24 |   }"},{"path":"tutorial-1-introduction.html","id":"test-the-code","chapter":"4 Tutorial 1: Introduction","heading":"4.4.8 Test the code","text":"action function look like .Try restart, load run code line line.","code":"## https://github.com/sykdomspulsen-org/sc-tutorial-end/blob/main/R/weather_download_and_import_rawdata.r#L1-L86\n## \n##  1 | # **** action **** ----\n##  2 | #' weather_download_and_import_rawdata (action)\n##  3 | #' @param data Data\n##  4 | #' @param argset Argset\n##  5 | #' @param schema DB Schema\n##  6 | #' @export\n##  7 | weather_download_and_import_rawdata_action <- function(data, argset, schema) {\n##  8 |   # tm_run_task(\"weather_download_and_import_rawdata\")\n##  9 | \n## 10 |   if (plnr::is_run_directly()) {\n## 11 |     # sc::tm_get_plans_argsets_as_dt(\"weather_download_and_import_rawdata\")\n## 12 | \n## 13 |     index_plan <- 1\n## 14 |     index_analysis <- 1\n## 15 | \n## 16 |     data <- sc::tm_get_data(\"weather_download_and_import_rawdata\", index_plan = index_plan)\n## 17 |     argset <- sc::tm_get_argset(\"weather_download_and_import_rawdata\", index_plan = index_plan, index_analysis = index_analysis)\n## 18 |     schema <- sc::tm_get_schema(\"weather_download_and_import_rawdata\")\n## 19 |   }\n## 20 | \n## 21 |   # special case that runs before everything\n## 22 |   if (argset$first_analysis == TRUE) {\n## 23 | \n## 24 |   }\n## 25 | \n## 26 |   a <- data$data\n## 27 | \n## 28 |   baz <- xml2::xml_find_all(a, \".//maxTemperature\")\n## 29 |   res <- vector(\"list\", length = length(baz))\n## 30 |   for (i in seq_along(baz)) {\n## 31 |     parent <- xml2::xml_parent(baz[[i]])\n## 32 |     grandparent <- xml2::xml_parent(parent)\n## 33 |     time_from <- xml2::xml_attr(grandparent, \"from\")\n## 34 |     time_to <- xml2::xml_attr(grandparent, \"to\")\n## 35 |     x <- xml2::xml_find_all(parent, \".//minTemperature\")\n## 36 |     temp_min <- xml2::xml_attr(x, \"value\")\n## 37 |     x <- xml2::xml_find_all(parent, \".//maxTemperature\")\n## 38 |     temp_max <- xml2::xml_attr(x, \"value\")\n## 39 |     x <- xml2::xml_find_all(parent, \".//precipitation\")\n## 40 |     precip <- xml2::xml_attr(x, \"value\")\n## 41 |     res[[i]] <- data.frame(\n## 42 |       time_from = as.character(time_from),\n## 43 |       time_to = as.character(time_to),\n## 44 |       temp_max = as.numeric(temp_max),\n## 45 |       temp_min = as.numeric(temp_min),\n## 46 |       precip = as.numeric(precip)\n## 47 |     )\n## 48 |   }\n## 49 |   res <- rbindlist(res)\n## 50 |   res <- res[stringr::str_sub(time_from, 12, 13) %in% c(\"00\", \"06\", \"12\", \"18\")]\n## 51 |   res[, date := as.Date(stringr::str_sub(time_from, 1, 10))]\n## 52 |   res[, N := .N, by = date]\n## 53 |   res <- res[N == 4]\n## 54 |   res <- res[\n## 55 |     ,\n## 56 |     .(\n## 57 |       temp_max = max(temp_max),\n## 58 |       temp_min = min(temp_min),\n## 59 |       precip = sum(precip)\n## 60 |     ),\n## 61 |     keyby = .(date)\n## 62 |   ]\n## 63 | \n## 64 |   # we look at the downloaded data\n## 65 |   # res\n## 66 | \n## 67 |   # we now need to format it\n## 68 |   res[, granularity_time := \"day\"]\n## 69 |   res[, sex := \"total\"]\n## 70 |   res[, age := \"total\"]\n## 71 |   res[, location_code := argset$location_code]\n## 72 | \n## 73 |   # fill in missing structural variables\n## 74 |   sc::fill_in_missing_v8(res, border = 2020)\n## 75 | \n## 76 |   # we look at the downloaded data\n## 77 |   # res\n## 78 | \n## 79 |   # put data in db table\n## 80 |   schema$anon_example_weather_rawdata$insert_data(res)\n## 81 | \n## 82 |   # special case that runs after everything\n## 83 |   if (argset$last_analysis == TRUE) {\n## 84 | \n## 85 |   }\n## 86 | }"},{"path":"tutorial-1-introduction.html","id":"which-plananalysis-is-which","chapter":"4 Tutorial 1: Introduction","heading":"4.4.9 Which plan/analysis is which?","text":"Inside (plnr::is_run_directly()) { sections, specify index_plan index_analysis. However, just numbers. want specifically look plan Oslo municipality, know index_plan corresponds ?Try change plan number run script .Now implemented first task creating schema, task description data selector function action function! Congratulations!Run entire task running tm_run_task(\"weather_download_and_import_rawdata\").","code":"\noptions(width = 150)\nsc::tm_get_plans_argsets_as_dt(\"weather_download_and_import_rawdata\")\n##      index_plan index_analysis **universal** **plan** location_code **analysis** **automatic** index      today  yesterday first_analysis\n##   1:          1              1             *        *   municip1820            *             *     1 2022-03-01 2022-02-28           TRUE\n##   2:          2              1             *        *   municip5403            *             *     2 2022-03-01 2022-02-28          FALSE\n##   3:          3              1             *        *   municip3428            *             *     3 2022-03-01 2022-02-28          FALSE\n##   4:          4              1             *        *   municip4631            *             *     4 2022-03-01 2022-02-28          FALSE\n##   5:          5              1             *        *   municip1871            *             *     5 2022-03-01 2022-02-28          FALSE\n##  ---                                                                                                                                     \n## 352:        352              1             *        *   municip3442            *             *   352 2022-03-01 2022-02-28          FALSE\n## 353:        353              1             *        *   municip3048            *             *   353 2022-03-01 2022-02-28          FALSE\n## 354:        354              1             *        *   municip3440            *             *   354 2022-03-01 2022-02-28          FALSE\n## 355:        355              1             *        *   municip4626            *             *   355 2022-03-01 2022-02-28          FALSE\n## 356:        356              1             *        *   municip3453            *             *   356 2022-03-01 2022-02-28          FALSE\n##      first_argset last_analysis last_argset\n##   1:         TRUE         FALSE       FALSE\n##   2:        FALSE         FALSE       FALSE\n##   3:        FALSE         FALSE       FALSE\n##   4:        FALSE         FALSE       FALSE\n##   5:        FALSE         FALSE       FALSE\n##  ---                                       \n## 352:        FALSE         FALSE       FALSE\n## 353:        FALSE         FALSE       FALSE\n## 354:        FALSE         FALSE       FALSE\n## 355:        FALSE         FALSE       FALSE\n## 356:        FALSE          TRUE        TRUE"},{"path":"tutorial-1-introduction.html","id":"developing-weather_clean_data","chapter":"4 Tutorial 1: Introduction","heading":"4.5 Developing weather_clean_data","text":"previous task (weather_download_and_import_rawdata) focused downloading raw data API inserting database table.task weather_clean_data focuses cleaning raw data inserting another database table. , data source Sykdomspulsen Core database table, output also Sykdomspulsen Core database table.walk development weather_clean_data, however, description task less comprehensive previous task, focus primarily parts novel.already mentioned weather_clean_data cleans raw data. want task take raw data obtained previous task aggregate obtain weather data different geographical regions municipalities. use pre-made FHI functions fhidata::make_skeleton makes data table skeleton regions interest fhidata::norway_locations_hierarchy converts location codes one location code level another.","code":""},{"path":"tutorial-1-introduction.html","id":"schemas-2","chapter":"4 Tutorial 1: Introduction","heading":"4.5.1 1. Schemas","text":"First start creating schema data want task store. structure exactly previous task name access anon temp_max, temp_min precip additional colums. Try create schema 03_db_schemas.r.","code":"## https://github.com/sykdomspulsen-org/sc-tutorial-end/blob/main/R/03_db_schemas.r#L66-L113\n## \n##  66 |   ## > anon_example_weather_data ----\n##  67 |   sc::add_schema_v8(\n##  68 |     name_access = c(\"anon\"),\n##  69 |     name_grouping = \"example_weather\",\n##  70 |     name_variant = \"data\",\n##  71 |     db_configs = sc::config$db_configs,\n##  72 |     field_types =  c(\n##  73 |       \"granularity_time\" = \"TEXT\",\n##  74 |       \"granularity_geo\" = \"TEXT\",\n##  75 |       \"country_iso3\" = \"TEXT\",\n##  76 |       \"location_code\" = \"TEXT\",\n##  77 |       \"border\" = \"INTEGER\",\n##  78 |       \"age\" = \"TEXT\",\n##  79 |       \"sex\" = \"TEXT\",\n##  80 | \n##  81 |       \"date\" = \"DATE\",\n##  82 | \n##  83 |       \"isoyear\" = \"INTEGER\",\n##  84 |       \"isoweek\" = \"INTEGER\",\n##  85 |       \"isoyearweek\" = \"TEXT\",\n##  86 |       \"season\" = \"TEXT\",\n##  87 |       \"seasonweek\" = \"DOUBLE\",\n##  88 | \n##  89 |       \"calyear\" = \"INTEGER\",\n##  90 |       \"calmonth\" = \"INTEGER\",\n##  91 |       \"calyearmonth\" = \"TEXT\",\n##  92 | \n##  93 |       \"temp_max\" = \"DOUBLE\",\n##  94 |       \"temp_min\" = \"DOUBLE\",\n##  95 |       \"precip\" = \"DOUBLE\"\n##  96 |     ),\n##  97 |     keys = c(\n##  98 |       \"granularity_time\",\n##  99 |       \"location_code\",\n## 100 |       \"date\",\n## 101 |       \"age\",\n## 102 |       \"sex\"\n## 103 |     ),\n## 104 |     censors = list(\n## 105 |       anon = list(\n## 106 | \n## 107 |       )\n## 108 |     ),\n## 109 |     validator_field_types = sc::validator_field_types_sykdomspulsen,\n## 110 |     validator_field_contents = sc::validator_field_contents_sykdomspulsen,\n## 111 |     info = \"This db table is used for...\"\n## 112 |   )\n## 113 |"},{"path":"tutorial-1-introduction.html","id":"task-definition-task_from_config-1","chapter":"4 Tutorial 1: Introduction","heading":"4.5.2 2. Task definition (task_from_config)","text":"next step define task 04_tasks.r . task aim aggregate data higher levels meaning need data available time preform entire task one analysis. Hence need task one plan (x = 1). need data database created previous task input schema schema just implemented output schema. Try create task definition! (Remember use addins menu get boiler plate task definition.)","code":""},{"path":"tutorial-1-introduction.html","id":"plananalysis-structure-1","chapter":"4 Tutorial 1: Introduction","heading":"4.5.2.1 Plan/analysis structure","text":"particular task, decided implement one plan containing one analysis, process data .aggregating municipality data county level, implemented 11 plans (one county). However, also aggregating national level, need data available .","code":"## https://github.com/sykdomspulsen-org/sc-tutorial-end/blob/main/R/04_tasks.r#L52-L56\n## \n## 52 |     plan_analysis_fn_name = NULL,\n## 53 |     for_each_plan = plnr::expand_list(\n## 54 |       x = 1\n## 55 |     ),\n## 56 |     for_each_analysis = NULL,"},{"path":"tutorial-1-introduction.html","id":"schemas-3","chapter":"4 Tutorial 1: Introduction","heading":"4.5.2.2 Schemas","text":"need specify schemas used input output.","code":"## https://github.com/sykdomspulsen-org/sc-tutorial-end/blob/main/R/04_tasks.r#L62-L68\n## \n## 62 |     schema = list(\n## 63 |       # input\n## 64 |       \"anon_example_weather_rawdata\" = sc::config$schemas$anon_example_weather_rawdata,\n## 65 | \n## 66 |       # output\n## 67 |       \"anon_example_weather_data\" = sc::config$schemas$anon_example_weather_data\n## 68 |     ),"},{"path":"tutorial-1-introduction.html","id":"full-task-description","chapter":"4 Tutorial 1: Introduction","heading":"4.5.2.3 Full task description","text":"","code":"## https://github.com/sykdomspulsen-org/sc-tutorial-end/blob/main/R/04_tasks.r#L45-L70\n## \n## 45 |   ## > weather_clean_data ----\n## 46 |   # tm_run_task(\"weather_clean_data\")\n## 47 |   sc::add_task_from_config_v8(\n## 48 |     name_grouping = \"weather\",\n## 49 |     name_action = \"clean_data\",\n## 50 |     name_variant = NULL,\n## 51 |     cores = 1,\n## 52 |     plan_analysis_fn_name = NULL,\n## 53 |     for_each_plan = plnr::expand_list(\n## 54 |       x = 1\n## 55 |     ),\n## 56 |     for_each_analysis = NULL,\n## 57 |     universal_argset = NULL,\n## 58 |     upsert_at_end_of_each_plan = FALSE,\n## 59 |     insert_at_end_of_each_plan = FALSE,\n## 60 |     action_fn_name = \"scexample::weather_clean_data_action\",\n## 61 |     data_selector_fn_name = \"scexample::weather_clean_data_data_selector\",\n## 62 |     schema = list(\n## 63 |       # input\n## 64 |       \"anon_example_weather_rawdata\" = sc::config$schemas$anon_example_weather_rawdata,\n## 65 | \n## 66 |       # output\n## 67 |       \"anon_example_weather_data\" = sc::config$schemas$anon_example_weather_data\n## 68 |     ),\n## 69 |     info = \"This task cleans the raw data and aggregates it to county and national level\"\n## 70 |   )"},{"path":"tutorial-1-introduction.html","id":"data_selector_fn-2","chapter":"4 Tutorial 1: Introduction","heading":"4.5.3 3. data_selector_fn","text":"Now ready create data selector function. Go script weather_clean_data. Use addins menu get boiler plate action function data selector function scroll data selector part. Start inserting task name instead TASK_NAME.","code":""},{"path":"tutorial-1-introduction.html","id":"getting-data-specify-the-schema","chapter":"4 Tutorial 1: Introduction","heading":"4.5.3.1 Getting data (specify the schema)","text":"Next fill inn name input schema instead SCHEMA_NAME, connecting database table linked schema.","code":"## https://github.com/sykdomspulsen-org/sc-tutorial-end/blob/main/R/weather_clean_data.r#L200-L200\n## \n## 200 |   d <- schema$anon_example_weather_rawdata$tbl() %>%"},{"path":"tutorial-1-introduction.html","id":"getting-data-scmandatory_db_filter","chapter":"4 Tutorial 1: Introduction","heading":"4.5.3.2 Getting data (sc::mandatory_db_filter)","text":"introduce sc::mandatory_db_filter. filter common structural variables. say “mandatory” want user always keep mind:minimal amount data needed jobTo explicit possible data needed jobFill inn mandatory filters best can take peak sure.notice don’t use arguments passed function, use many can.","code":"## https://github.com/sykdomspulsen-org/sc-tutorial-end/blob/main/R/weather_clean_data.r#L201-L212\n## \n## 201 |     sc::mandatory_db_filter(\n## 202 |       granularity_time = \"day\",\n## 203 |       granularity_time_not = NULL,\n## 204 |       granularity_geo = \"municip\",\n## 205 |       granularity_geo_not = NULL,\n## 206 |       country_iso3 = NULL,\n## 207 |       location_code = NULL,\n## 208 |       age = \"total\",\n## 209 |       age_not = NULL,\n## 210 |       sex = \"total\",\n## 211 |       sex_not = NULL\n## 212 |     ) %>%"},{"path":"tutorial-1-introduction.html","id":"getting-data-dplyrselect","chapter":"4 Tutorial 1: Introduction","heading":"4.5.3.3 Getting data (dplyr::select)","text":"always want explicit possible data needed job. achieve , use dplyr::select select columns interested .want quickly generate dplyr::select boilerplate schema can copy/paste, can via either following:Use one functions replace dplyr::select part data selector function. aggregate data need location_code, date, temp_max, temp_min, precip, granularity_time (dayly, weekly, etc). Comment variables.","code":"\nschema$anon_example_weather_rawdata$print_dplyr_select()## dplyr::select(\n##   granularity_time,\n##   granularity_geo,\n##   country_iso3,\n##   location_code,\n##   border,\n##   age,\n##   sex,\n##   date,\n##   isoyear,\n##   isoweek,\n##   isoyearweek,\n##   season,\n##   seasonweek,\n##   calyear,\n##   calmonth,\n##   calyearmonth,\n##   temp_max,\n##   temp_min,\n##   precip\n## ) %>%## https://github.com/sykdomspulsen-org/sc-tutorial-end/blob/main/R/weather_clean_data.r#L213-L237\n## \n## 213 |     dplyr::select(\n## 214 |       granularity_time,\n## 215 |       # granularity_geo,\n## 216 |       # country_iso3,\n## 217 |       location_code,\n## 218 |       # border,\n## 219 |       # age,\n## 220 |       # sex,\n## 221 | \n## 222 |       date,\n## 223 | \n## 224 |       # isoyear,\n## 225 |       # isoweek,\n## 226 |       # isoyearweek,\n## 227 |       # season,\n## 228 |       # seasonweek,\n## 229 | \n## 230 |       # calyear,\n## 231 |       # calmonth,\n## 232 |       # calyearmonth,\n## 233 | \n## 234 |       temp_max,\n## 235 |       temp_min,\n## 236 |       precip\n## 237 |     ) %>%"},{"path":"tutorial-1-introduction.html","id":"getting-data-dplyrcollect","chapter":"4 Tutorial 1: Introduction","heading":"4.5.3.4 Getting data (dplyr::collect)","text":"executes SQL call database.","code":"## https://github.com/sykdomspulsen-org/sc-tutorial-end/blob/main/R/weather_clean_data.r#L238-L238\n## \n## 238 |     dplyr::collect() %>%"},{"path":"tutorial-1-introduction.html","id":"getting-data-data.table-and-setorder","chapter":"4 Tutorial 1: Introduction","heading":"4.5.3.5 Getting data (data.table and setorder)","text":"Firstly, general rule prefer use data.table. like convert data.frame data.table.Secondly, guaranteed receive data particular order. , important sort data arrival (relevant action_fn, e.g. cumulative sums created).","code":"## https://github.com/sykdomspulsen-org/sc-tutorial-end/blob/main/R/weather_clean_data.r#L239-L243\n## \n## 239 |     as.data.table() %>%\n## 240 |     setorder(\n## 241 |       location_code,\n## 242 |       date\n## 243 |     )"},{"path":"tutorial-1-introduction.html","id":"set-a-name","chapter":"4 Tutorial 1: Introduction","heading":"4.5.3.6 Set a name","text":"Finally give dataset return suitable name example day_municip.Check data selector function works saving, restarting, loading packages. run function line line.","code":""},{"path":"tutorial-1-introduction.html","id":"example-of-the-data_selector-function","chapter":"4 Tutorial 1: Introduction","heading":"4.5.3.7 Example of the data_selector function","text":"","code":"## https://github.com/sykdomspulsen-org/sc-tutorial-end/blob/main/R/weather_clean_data.r#L184-L251\n## \n## 184 | # **** data_selector **** ----\n## 185 | #' weather_clean_data (data selector)\n## 186 | #' @param argset Argset\n## 187 | #' @param schema DB Schema\n## 188 | #' @export\n## 189 | weather_clean_data_data_selector <- function(argset, schema) {\n## 190 |   if (plnr::is_run_directly()) {\n## 191 |     # sc::tm_get_plans_argsets_as_dt(\"weather_clean_data\")\n## 192 | \n## 193 |     index_plan <- 1\n## 194 | \n## 195 |     argset <- sc::tm_get_argset(\"weather_clean_data\", index_plan = index_plan)\n## 196 |     schema <- sc::tm_get_schema(\"weather_clean_data\")\n## 197 |   }\n## 198 | \n## 199 |   # The database schemas can be accessed here\n## 200 |   d <- schema$anon_example_weather_rawdata$tbl() %>%\n## 201 |     sc::mandatory_db_filter(\n## 202 |       granularity_time = \"day\",\n## 203 |       granularity_time_not = NULL,\n## 204 |       granularity_geo = \"municip\",\n## 205 |       granularity_geo_not = NULL,\n## 206 |       country_iso3 = NULL,\n## 207 |       location_code = NULL,\n## 208 |       age = \"total\",\n## 209 |       age_not = NULL,\n## 210 |       sex = \"total\",\n## 211 |       sex_not = NULL\n## 212 |     ) %>%\n## 213 |     dplyr::select(\n## 214 |       granularity_time,\n## 215 |       # granularity_geo,\n## 216 |       # country_iso3,\n## 217 |       location_code,\n## 218 |       # border,\n## 219 |       # age,\n## 220 |       # sex,\n## 221 | \n## 222 |       date,\n## 223 | \n## 224 |       # isoyear,\n## 225 |       # isoweek,\n## 226 |       # isoyearweek,\n## 227 |       # season,\n## 228 |       # seasonweek,\n## 229 | \n## 230 |       # calyear,\n## 231 |       # calmonth,\n## 232 |       # calyearmonth,\n## 233 | \n## 234 |       temp_max,\n## 235 |       temp_min,\n## 236 |       precip\n## 237 |     ) %>%\n## 238 |     dplyr::collect() %>%\n## 239 |     as.data.table() %>%\n## 240 |     setorder(\n## 241 |       location_code,\n## 242 |       date\n## 243 |     )\n## 244 | \n## 245 |   # The variable returned must be a named list\n## 246 |   retval <- list(\n## 247 |     \"day_municip\" = d\n## 248 |   )\n## 249 | \n## 250 |   retval\n## 251 | }"},{"path":"tutorial-1-introduction.html","id":"action_fn-2","chapter":"4 Tutorial 1: Introduction","heading":"4.5.4 4. action_fn","text":"final step process creating action function. Replace TASK_NAME task name.","code":""},{"path":"tutorial-1-introduction.html","id":"skeleton","chapter":"4 Tutorial 1: Introduction","heading":"4.5.4.1 Skeleton","text":"action function use fhi skeletons create bases data tables.\nRead concept skeletons.Start creating variable (example d_agg) empty list copy data collected data selector function (d_agg$day_municip <- copy(data$day_municip)). Extract first last date dataset.Now going create skeleton separate regions data (municipalities) regions data (bo og arbeigs regioner). skeleton function takes min max dates case pass granularity_geo consisting list ","code":"\nlist(\n          \"nodata\" = c(\n          \"wardoslo\",\n          \"extrawardoslo\",\n          \"missingwardoslo\",\n          \"wardbergen\",\n          \"missingwardbergen\",\n          \"wardstavanger\",\n          \"missingwardstavanger\",\n          \"notmainlandmunicip\",\n          \"missingmunicip\",\n          \"notmainlandcounty\",\n          \"missingcounty\"\n        ),\n        \"municip\" = c(\n          \"municip\"\n        )\n)\n## $nodata\n##  [1] \"wardoslo\"             \"extrawardoslo\"        \"missingwardoslo\"      \"wardbergen\"           \"missingwardbergen\"    \"wardstavanger\"       \n##  [7] \"missingwardstavanger\" \"notmainlandmunicip\"   \"missingmunicip\"       \"notmainlandcounty\"    \"missingcounty\"       \n## \n## $municip\n## [1] \"municip\""},{"path":"tutorial-1-introduction.html","id":"merge-in-weather-data","chapter":"4 Tutorial 1: Introduction","heading":"4.5.4.2 Merge in weather data","text":"Next want merge information weather data municipalities data.","code":"## https://github.com/sykdomspulsen-org/sc-tutorial-end/blob/main/R/weather_clean_data.r#L67-L84\n## \n## 67 |   # Merge in the information you have at different geographical granularities\n## 68 |   # one level at a time\n## 69 |   # municip\n## 70 |   multiskeleton_day$municip[\n## 71 |     d_agg$day_municip,\n## 72 |     on = c(\"location_code\", \"date\"),\n## 73 |     c(\n## 74 |       \"temp_max\",\n## 75 |       \"temp_min\",\n## 76 |       \"precip\"\n## 77 |     ) := .(\n## 78 |       temp_max,\n## 79 |       temp_min,\n## 80 |       precip\n## 81 |     )\n## 82 |   ]\n## 83 | \n## 84 |   multiskeleton_day$municip[]"},{"path":"tutorial-1-introduction.html","id":"aggregate-to-a-county-level","chapter":"4 Tutorial 1: Introduction","heading":"4.5.4.3 Aggregate to a county level","text":"Now aggregate data county level help fhidata::norway_locations_hierarchy","code":"## https://github.com/sykdomspulsen-org/sc-tutorial-end/blob/main/R/weather_clean_data.r#L86-L109\n## \n##  86 |   # Aggregate up to higher geographical granularities (county)\n##  87 |   multiskeleton_day$county <- multiskeleton_day$municip[\n##  88 |     fhidata::norway_locations_hierarchy(\n##  89 |       from = \"municip\",\n##  90 |       to = \"county\"\n##  91 |     ),\n##  92 |     on = c(\n##  93 |       \"location_code==from_code\"\n##  94 |     )\n##  95 |   ][,\n##  96 |     .(\n##  97 |       temp_max = mean(temp_max, na.rm = T),\n##  98 |       temp_min = mean(temp_min, na.rm = T),\n##  99 |       precip = mean(precip, na.rm = T),\n## 100 |       granularity_geo = \"county\"\n## 101 |     ),\n## 102 |     by = .(\n## 103 |       granularity_time,\n## 104 |       date,\n## 105 |       location_code = to_code\n## 106 |     )\n## 107 |   ]\n## 108 | \n## 109 |   multiskeleton_day$county[]"},{"path":"tutorial-1-introduction.html","id":"aggregate-to-national-level","chapter":"4 Tutorial 1: Introduction","heading":"4.5.4.4 Aggregate to national level","text":"overlap municipalities, hence aggregating national level can done without help fhidata::norway_locations_hierarchy.","code":"## https://github.com/sykdomspulsen-org/sc-tutorial-end/blob/main/R/weather_clean_data.r#L111-L127\n## \n## 111 |   # Aggregate up to higher geographical granularities (nation)\n## 112 |   multiskeleton_day$nation <- multiskeleton_day$municip[\n## 113 |     ,\n## 114 |     .(\n## 115 |       temp_max = mean(temp_max, na.rm = T),\n## 116 |       temp_min = mean(temp_min, na.rm = T),\n## 117 |       precip = mean(precip, na.rm = T),\n## 118 |       granularity_geo = \"nation\",\n## 119 |       location_code = \"norge\"\n## 120 |     ),\n## 121 |     by = .(\n## 122 |       granularity_time,\n## 123 |       date\n## 124 |     )\n## 125 |   ]\n## 126 | \n## 127 |   multiskeleton_day$nation[]"},{"path":"tutorial-1-introduction.html","id":"combine-data","chapter":"4 Tutorial 1: Introduction","heading":"4.5.4.5 Combine data","text":"Combine different granularity geos using rbindlist storing new name f.eks skeleton_day.","code":""},{"path":"tutorial-1-introduction.html","id":"weekly-data.","chapter":"4 Tutorial 1: Introduction","heading":"4.5.4.6 Weekly data.","text":"challenge try aggregate daily data weekly data! can use fhiplot::isoyearweek_c(date) get isoweek date.","code":"## https://github.com/sykdomspulsen-org/sc-tutorial-end/blob/main/R/weather_clean_data.r#L134-L153\n## \n## 134 |   # 10. (If desirable) aggregate up to higher time granularities\n## 135 |   # if necessary, it is now easy to aggregate up to weekly data from here\n## 136 |   skeleton_isoweek <- copy(skeleton_day)\n## 137 |   skeleton_isoweek[, isoyearweek := fhiplot::isoyearweek_c(date)]\n## 138 |   skeleton_isoweek <- skeleton_isoweek[\n## 139 |     ,\n## 140 |     .(\n## 141 |       temp_max = mean(temp_max, na.rm = T),\n## 142 |       temp_min = mean(temp_min, na.rm = T),\n## 143 |       precip = mean(precip, na.rm = T),\n## 144 |       granularity_time = \"isoweek\"\n## 145 |     ),\n## 146 |     keyby = .(\n## 147 |       isoyearweek,\n## 148 |       granularity_geo,\n## 149 |       location_code\n## 150 |     )\n## 151 |   ]\n## 152 | \n## 153 |   skeleton_isoweek[]"},{"path":"tutorial-1-introduction.html","id":"structural-data","chapter":"4 Tutorial 1: Introduction","heading":"4.5.4.7 Structural data","text":"next step fill missing structural data. Fill sex = “total” age= “total” manually can use sc::fill_in_missing_v8(skeleton_day, border = config$border).\nweekly data make sure also convert date using .Date(date) ensure right format.Rbindlist binds two data tables together.","code":"## https://github.com/sykdomspulsen-org/sc-tutorial-end/blob/main/R/weather_clean_data.r#L155-L173\n## \n## 155 |   # we now need to format it and fill in missing structural variables\n## 156 |   # day\n## 157 |   skeleton_day[, sex := \"total\"]\n## 158 |   skeleton_day[, age := \"total\"]\n## 159 |   sc::fill_in_missing_v8(skeleton_day, border = config$border)\n## 160 | \n## 161 |   # isoweek\n## 162 |   skeleton_isoweek[, sex := \"total\"]\n## 163 |   skeleton_isoweek[, age := \"total\"]\n## 164 |   sc::fill_in_missing_v8(skeleton_isoweek, border = config$border)\n## 165 |   skeleton_isoweek[, date := as.Date(date)]\n## 166 | \n## 167 |   skeleton <- rbindlist(\n## 168 |     list(\n## 169 |       skeleton_day,\n## 170 |       skeleton_isoweek\n## 171 |     ),\n## 172 |     use.names = T\n## 173 |   )"},{"path":"tutorial-1-introduction.html","id":"store-the-data","chapter":"4 Tutorial 1: Introduction","heading":"4.5.4.8 Store the data","text":"Insert final data table database specified task descriptionRestart R, load packages try run task.Run entire task running tm_run_task(\"weather_clean_data\"). ran tasks beginning script might need run schema$anon_example_weather_data$drop_all_rows() first.","code":"## https://github.com/sykdomspulsen-org/sc-tutorial-end/blob/main/R/weather_clean_data.r#L175-L176\n## \n## 175 |   # put data in db table\n## 176 |   schema$anon_example_weather_data$drop_all_rows_and_then_insert_data(skeleton)"},{"path":"tutorial-1-introduction.html","id":"full-example","chapter":"4 Tutorial 1: Introduction","heading":"4.5.4.9 Full example","text":"","code":"## https://github.com/sykdomspulsen-org/sc-tutorial-end/blob/main/R/weather_clean_data.r#L1-L182\n## \n##   1 | # **** action **** ----\n##   2 | #' weather_clean_data (action)\n##   3 | #' @param data Data\n##   4 | #' @param argset Argset\n##   5 | #' @param schema DB Schema\n##   6 | #' @export\n##   7 | weather_clean_data_action <- function(data, argset, schema) {\n##   8 |   # tm_run_task(\"weather_clean_data\")\n##   9 | \n##  10 |   if (plnr::is_run_directly()) {\n##  11 |     # sc::tm_get_plans_argsets_as_dt(\"weather_clean_data\")\n##  12 | \n##  13 |     index_plan <- 1\n##  14 |     index_analysis <- 1\n##  15 | \n##  16 |     data <- sc::tm_get_data(\"weather_clean_data\", index_plan = index_plan)\n##  17 |     argset <- sc::tm_get_argset(\"weather_clean_data\", index_plan = index_plan, index_analysis = index_analysis)\n##  18 |     schema <- sc::tm_get_schema(\"weather_clean_data\")\n##  19 |   }\n##  20 | \n##  21 |   # special case that runs before everything\n##  22 |   if (argset$first_analysis == TRUE) {\n##  23 | \n##  24 |   }\n##  25 | \n##  26 |   # make sure there's no missing data via the creation of a skeleton\n##  27 |   # https://folkehelseinstituttet.github.io/fhidata/articles/Skeletons.html\n##  28 | \n##  29 |   # Create a variable (possibly a list) to hold the data\n##  30 |   d_agg <- list()\n##  31 |   d_agg$day_municip <- copy(data$day_municip)\n##  32 | \n##  33 |   # Pull out important dates\n##  34 |   date_min <- min(d_agg$day_municip$date, na.rm = T)\n##  35 |   date_max <- max(d_agg$day_municip$date, na.rm = T)\n##  36 | \n##  37 |   # Create `multiskeleton`\n##  38 |   # granularity_geo should have the following groups:\n##  39 |   # - nodata (when no data is available, and there is no \"finer\" data available to aggregate up)\n##  40 |   # - all levels of granularity_geo where you have data available\n##  41 |   # If you do not have data for a specific granularity_geo, but there is \"finer\" data available\n##  42 |   # then you should not include this granularity_geo in the multiskeleton, because you will create\n##  43 |   # it later when you aggregate up your data (baregion)\n##  44 |   multiskeleton_day <- fhidata::make_skeleton(\n##  45 |     date_min = date_min,\n##  46 |     date_max = date_max,\n##  47 |     granularity_geo = list(\n##  48 |       \"nodata\" = c(\n##  49 |         \"wardoslo\",\n##  50 |         \"extrawardoslo\",\n##  51 |         \"missingwardoslo\",\n##  52 |         \"wardbergen\",\n##  53 |         \"missingwardbergen\",\n##  54 |         \"wardstavanger\",\n##  55 |         \"missingwardstavanger\",\n##  56 |         \"notmainlandmunicip\",\n##  57 |         \"missingmunicip\",\n##  58 |         \"notmainlandcounty\",\n##  59 |         \"missingcounty\"\n##  60 |       ),\n##  61 |       \"municip\" = c(\n##  62 |         \"municip\"\n##  63 |       )\n##  64 |     )\n##  65 |   )\n##  66 | \n##  67 |   # Merge in the information you have at different geographical granularities\n##  68 |   # one level at a time\n##  69 |   # municip\n##  70 |   multiskeleton_day$municip[\n##  71 |     d_agg$day_municip,\n##  72 |     on = c(\"location_code\", \"date\"),\n##  73 |     c(\n##  74 |       \"temp_max\",\n##  75 |       \"temp_min\",\n##  76 |       \"precip\"\n##  77 |     ) := .(\n##  78 |       temp_max,\n##  79 |       temp_min,\n##  80 |       precip\n##  81 |     )\n##  82 |   ]\n##  83 | \n##  84 |   multiskeleton_day$municip[]\n##  85 | \n##  86 |   # Aggregate up to higher geographical granularities (county)\n##  87 |   multiskeleton_day$county <- multiskeleton_day$municip[\n##  88 |     fhidata::norway_locations_hierarchy(\n##  89 |       from = \"municip\",\n##  90 |       to = \"county\"\n##  91 |     ),\n##  92 |     on = c(\n##  93 |       \"location_code==from_code\"\n##  94 |     )\n##  95 |   ][,\n##  96 |     .(\n##  97 |       temp_max = mean(temp_max, na.rm = T),\n##  98 |       temp_min = mean(temp_min, na.rm = T),\n##  99 |       precip = mean(precip, na.rm = T),\n## 100 |       granularity_geo = \"county\"\n## 101 |     ),\n## 102 |     by = .(\n## 103 |       granularity_time,\n## 104 |       date,\n## 105 |       location_code = to_code\n## 106 |     )\n## 107 |   ]\n## 108 | \n## 109 |   multiskeleton_day$county[]\n## 110 | \n## 111 |   # Aggregate up to higher geographical granularities (nation)\n## 112 |   multiskeleton_day$nation <- multiskeleton_day$municip[\n## 113 |     ,\n## 114 |     .(\n## 115 |       temp_max = mean(temp_max, na.rm = T),\n## 116 |       temp_min = mean(temp_min, na.rm = T),\n## 117 |       precip = mean(precip, na.rm = T),\n## 118 |       granularity_geo = \"nation\",\n## 119 |       location_code = \"norge\"\n## 120 |     ),\n## 121 |     by = .(\n## 122 |       granularity_time,\n## 123 |       date\n## 124 |     )\n## 125 |   ]\n## 126 | \n## 127 |   multiskeleton_day$nation[]\n## 128 | \n## 129 |   # combine all the different granularity_geos\n## 130 |   skeleton_day <- rbindlist(multiskeleton_day, fill = TRUE, use.names = TRUE)\n## 131 | \n## 132 |   skeleton_day[]\n## 133 | \n## 134 |   # 10. (If desirable) aggregate up to higher time granularities\n## 135 |   # if necessary, it is now easy to aggregate up to weekly data from here\n## 136 |   skeleton_isoweek <- copy(skeleton_day)\n## 137 |   skeleton_isoweek[, isoyearweek := fhiplot::isoyearweek_c(date)]\n## 138 |   skeleton_isoweek <- skeleton_isoweek[\n## 139 |     ,\n## 140 |     .(\n## 141 |       temp_max = mean(temp_max, na.rm = T),\n## 142 |       temp_min = mean(temp_min, na.rm = T),\n## 143 |       precip = mean(precip, na.rm = T),\n## 144 |       granularity_time = \"isoweek\"\n## 145 |     ),\n## 146 |     keyby = .(\n## 147 |       isoyearweek,\n## 148 |       granularity_geo,\n## 149 |       location_code\n## 150 |     )\n## 151 |   ]\n## 152 | \n## 153 |   skeleton_isoweek[]\n## 154 | \n## 155 |   # we now need to format it and fill in missing structural variables\n## 156 |   # day\n## 157 |   skeleton_day[, sex := \"total\"]\n## 158 |   skeleton_day[, age := \"total\"]\n## 159 |   sc::fill_in_missing_v8(skeleton_day, border = config$border)\n## 160 | \n## 161 |   # isoweek\n## 162 |   skeleton_isoweek[, sex := \"total\"]\n## 163 |   skeleton_isoweek[, age := \"total\"]\n## 164 |   sc::fill_in_missing_v8(skeleton_isoweek, border = config$border)\n## 165 |   skeleton_isoweek[, date := as.Date(date)]\n## 166 | \n## 167 |   skeleton <- rbindlist(\n## 168 |     list(\n## 169 |       skeleton_day,\n## 170 |       skeleton_isoweek\n## 171 |     ),\n## 172 |     use.names = T\n## 173 |   )\n## 174 | \n## 175 |   # put data in db table\n## 176 |   schema$anon_example_weather_data$drop_all_rows_and_then_insert_data(skeleton)\n## 177 | \n## 178 |   # special case that runs after everything\n## 179 |   if (argset$last_analysis == TRUE) {\n## 180 | \n## 181 |   }\n## 182 | }"},{"path":"tutorial-1-introduction.html","id":"developing-weather_export_plots","chapter":"4 Tutorial 1: Introduction","heading":"4.6 Developing weather_export_plots","text":"final task tutorial, weather_export_plots, takes cleaned data plots 11 graphs (one county) min max temperatures.\nmeans need 11 plans, one county. use input data generated data clean_weather_data. Hence, need create new schema. going pass universal argset task definition define location store figures.benefits placing output directories filenames task declaration :makes action_fn generic, can reused multiple tasksIt easier get overview output sent“decisions” task config “fewer decisions” action_fn makes system easier everyone understand, decisions become explicitEverything inside curly brackets get passed action function.plan need data specific location_code. can implemented manditory filters data selector function.fs::dir_create(glue::glue(argset$output_dir)) can used create output directory.Try putting everything learned fare together create task . get stuck can always peak . Good luck!","code":"## https://github.com/sykdomspulsen-org/sc-tutorial-end/blob/main/R/weather_clean_data.r#L84-L88\n## \n## 84 |   multiskeleton_day$municip[]\n## 85 | \n## 86 |   # Aggregate up to higher geographical granularities (county)\n## 87 |   multiskeleton_day$county <- multiskeleton_day$municip[\n## 88 |     fhidata::norway_locations_hierarchy("},{"path":"tutorial-1-introduction.html","id":"schemas-4","chapter":"4 Tutorial 1: Introduction","heading":"4.6.1 1. Schemas","text":"schema already created previous task weather_clean_data.","code":"## https://github.com/sykdomspulsen-org/sc-tutorial-end/blob/main/R/03_db_schemas.r#L66-L112\n## \n##  66 |   ## > anon_example_weather_data ----\n##  67 |   sc::add_schema_v8(\n##  68 |     name_access = c(\"anon\"),\n##  69 |     name_grouping = \"example_weather\",\n##  70 |     name_variant = \"data\",\n##  71 |     db_configs = sc::config$db_configs,\n##  72 |     field_types =  c(\n##  73 |       \"granularity_time\" = \"TEXT\",\n##  74 |       \"granularity_geo\" = \"TEXT\",\n##  75 |       \"country_iso3\" = \"TEXT\",\n##  76 |       \"location_code\" = \"TEXT\",\n##  77 |       \"border\" = \"INTEGER\",\n##  78 |       \"age\" = \"TEXT\",\n##  79 |       \"sex\" = \"TEXT\",\n##  80 | \n##  81 |       \"date\" = \"DATE\",\n##  82 | \n##  83 |       \"isoyear\" = \"INTEGER\",\n##  84 |       \"isoweek\" = \"INTEGER\",\n##  85 |       \"isoyearweek\" = \"TEXT\",\n##  86 |       \"season\" = \"TEXT\",\n##  87 |       \"seasonweek\" = \"DOUBLE\",\n##  88 | \n##  89 |       \"calyear\" = \"INTEGER\",\n##  90 |       \"calmonth\" = \"INTEGER\",\n##  91 |       \"calyearmonth\" = \"TEXT\",\n##  92 | \n##  93 |       \"temp_max\" = \"DOUBLE\",\n##  94 |       \"temp_min\" = \"DOUBLE\",\n##  95 |       \"precip\" = \"DOUBLE\"\n##  96 |     ),\n##  97 |     keys = c(\n##  98 |       \"granularity_time\",\n##  99 |       \"location_code\",\n## 100 |       \"date\",\n## 101 |       \"age\",\n## 102 |       \"sex\"\n## 103 |     ),\n## 104 |     censors = list(\n## 105 |       anon = list(\n## 106 | \n## 107 |       )\n## 108 |     ),\n## 109 |     validator_field_types = sc::validator_field_types_sykdomspulsen,\n## 110 |     validator_field_contents = sc::validator_field_contents_sykdomspulsen,\n## 111 |     info = \"This db table is used for...\"\n## 112 |   )"},{"path":"tutorial-1-introduction.html","id":"task-definition-task_from_config-2","chapter":"4 Tutorial 1: Introduction","heading":"4.6.2 2. Task definition (task_from_config)","text":"","code":"## https://github.com/sykdomspulsen-org/sc-tutorial-end/blob/main/R/04_tasks.r#L72-L100\n## \n##  72 |   ## > weather_clean_data ----\n##  73 |   # tm_run_task(\"weather_export_plots\")\n##  74 |   sc::add_task_from_config_v8(\n##  75 |     name_grouping = \"weather\",\n##  76 |     name_action = \"export_plots\",\n##  77 |     name_variant = NULL,\n##  78 |     cores = 1,\n##  79 |     plan_analysis_fn_name = NULL,\n##  80 |     for_each_plan = plnr::expand_list(\n##  81 |       location_code = fhidata::norway_locations_names()[granularity_geo %in% c(\"county\")]$location_code\n##  82 |     ),\n##  83 |     for_each_analysis = NULL,\n##  84 |     universal_argset = list(\n##  85 |       output_dir = tempdir(),\n##  86 |       output_filename = \"weather_{argset$location_code}.png\",\n##  87 |       output_absolute_path = fs::path(\"{argset$output_dir}\", \"{argset$output_filename}\")\n##  88 |     ),\n##  89 |     upsert_at_end_of_each_plan = FALSE,\n##  90 |     insert_at_end_of_each_plan = FALSE,\n##  91 |     action_fn_name = \"scexample::weather_export_plots_action\",\n##  92 |     data_selector_fn_name = \"scexample::weather_export_plots_data_selector\",\n##  93 |     schema = list(\n##  94 |       # input\n##  95 |       \"anon_example_weather_data\" = sc::config$schemas$anon_example_weather_data\n##  96 | \n##  97 |       # output\n##  98 |     ),\n##  99 |     info = \"This task ploduces plots\"\n## 100 |   )"},{"path":"tutorial-1-introduction.html","id":"plananalysis-structure-2","chapter":"4 Tutorial 1: Introduction","heading":"4.6.2.1 Plan/analysis structure","text":"choose plan-heavy approach (11 plans, 1 analysis per plan) minimize amount data loaded RAM point time.","code":"## https://github.com/sykdomspulsen-org/sc-tutorial-end/blob/main/R/04_tasks.r#L79-L83\n## \n## 79 |     plan_analysis_fn_name = NULL,\n## 80 |     for_each_plan = plnr::expand_list(\n## 81 |       location_code = fhidata::norway_locations_names()[granularity_geo %in% c(\"county\")]$location_code\n## 82 |     ),\n## 83 |     for_each_analysis = NULL,"},{"path":"tutorial-1-introduction.html","id":"universal-argset-1","chapter":"4 Tutorial 1: Introduction","heading":"4.6.2.2 Universal argset","text":"","code":"## https://github.com/sykdomspulsen-org/sc-tutorial-end/blob/main/R/04_tasks.r#L84-L88\n## \n## 84 |     universal_argset = list(\n## 85 |       output_dir = tempdir(),\n## 86 |       output_filename = \"weather_{argset$location_code}.png\",\n## 87 |       output_absolute_path = fs::path(\"{argset$output_dir}\", \"{argset$output_filename}\")\n## 88 |     ),"},{"path":"tutorial-1-introduction.html","id":"data_selector_fn-3","chapter":"4 Tutorial 1: Introduction","heading":"4.6.3 3. data_selector_fn","text":"","code":"## https://github.com/sykdomspulsen-org/sc-tutorial-end/blob/main/R/weather_export_plots.r#L45-L110\n## \n##  45 | # **** data_selector **** ----\n##  46 | #' weather_export_plots (data selector)\n##  47 | #' @param argset Argset\n##  48 | #' @param schema DB Schema\n##  49 | #' @export\n##  50 | weather_export_plots_data_selector = function(argset, schema){\n##  51 |   if(plnr::is_run_directly()){\n##  52 |     # sc::tm_get_plans_argsets_as_dt(\"weather_export_plots\")\n##  53 | \n##  54 |     index_plan <- 1\n##  55 | \n##  56 |     argset <- sc::tm_get_argset(\"weather_export_plots\", index_plan = index_plan)\n##  57 |     schema <- sc::tm_get_schema(\"weather_export_plots\")\n##  58 |   }\n##  59 | \n##  60 |   # The database schemas can be accessed here\n##  61 |   d <- schema$anon_example_weather_data$tbl() %>%\n##  62 |     sc::mandatory_db_filter(\n##  63 |       granularity_time = NULL,\n##  64 |       granularity_time_not = NULL,\n##  65 |       granularity_geo = NULL,\n##  66 |       granularity_geo_not = NULL,\n##  67 |       country_iso3 = NULL,\n##  68 |       location_code = argset$location_code,\n##  69 |       age = NULL,\n##  70 |       age_not = NULL,\n##  71 |       sex = NULL,\n##  72 |       sex_not = NULL\n##  73 |     ) %>%\n##  74 |     dplyr::select(\n##  75 |       # granularity_time,\n##  76 |       # granularity_geo,\n##  77 |       # country_iso3,\n##  78 |       # location_code,\n##  79 |       # border,\n##  80 |       # age,\n##  81 |       # sex,\n##  82 | \n##  83 |       date,\n##  84 | \n##  85 |       # isoyear,\n##  86 |       # isoweek,\n##  87 |       # isoyearweek,\n##  88 |       # season,\n##  89 |       # seasonweek,\n##  90 |       #\n##  91 |       # calyear,\n##  92 |       # calmonth,\n##  93 |       # calyearmonth,\n##  94 | \n##  95 |       temp_max,\n##  96 |       temp_min\n##  97 |     ) %>%\n##  98 |     dplyr::collect() %>%\n##  99 |     as.data.table() %>%\n## 100 |     setorder(\n## 101 |       # location_code,\n## 102 |       date\n## 103 |     )\n## 104 | \n## 105 |   # The variable returned must be a named list\n## 106 |   retval <- list(\n## 107 |     \"data\" = d\n## 108 |   )\n## 109 |   retval\n## 110 | }"},{"path":"tutorial-1-introduction.html","id":"action_fn-3","chapter":"4 Tutorial 1: Introduction","heading":"4.6.4 4. action_fn","text":"","code":"## https://github.com/sykdomspulsen-org/sc-tutorial-end/blob/main/R/weather_export_plots.r#L1-L43\n## \n##  1 | # **** action **** ----\n##  2 | #' weather_export_plots (action)\n##  3 | #' @param data Data\n##  4 | #' @param argset Argset\n##  5 | #' @param schema DB Schema\n##  6 | #' @export\n##  7 | weather_export_plots_action <- function(data, argset, schema) {\n##  8 |   # tm_run_task(\"weather_export_plots\")\n##  9 | \n## 10 |   if(plnr::is_run_directly()){\n## 11 |     # sc::tm_get_plans_argsets_as_dt(\"weather_export_plots\")\n## 12 | \n## 13 |     index_plan <- 1\n## 14 |     index_analysis <- 1\n## 15 | \n## 16 |     data <- sc::tm_get_data(\"weather_export_plots\", index_plan = index_plan)\n## 17 |     argset <- sc::tm_get_argset(\"weather_export_plots\", index_plan = index_plan, index_analysis = index_analysis)\n## 18 |     schema <- sc::tm_get_schema(\"weather_export_plots\")\n## 19 |   }\n## 20 | \n## 21 |   # code goes here\n## 22 |   # special case that runs before everything\n## 23 |   if(argset$first_analysis == TRUE){\n## 24 | \n## 25 |   }\n## 26 | \n## 27 |   # create the output_dir (if it doesn't exist)\n## 28 |   fs::dir_create(glue::glue(argset$output_dir))\n## 29 | \n## 30 |   q <- ggplot(data$data, aes(x = date, ymin = temp_min, ymax = temp_max))\n## 31 |   q <- q + geom_ribbon(alpha = 0.5)\n## 32 | \n## 33 |   ggsave(\n## 34 |     filename = glue::glue(argset$output_absolute_path),\n## 35 |     plot = q\n## 36 |   )\n## 37 | \n## 38 |   # special case that runs after everything\n## 39 |   # copy to anon_web?\n## 40 |   if(argset$last_analysis == TRUE){\n## 41 | \n## 42 |   }\n## 43 | }"},{"path":"tutorial-1-introduction.html","id":"final-package","chapter":"4 Tutorial 1: Introduction","heading":"4.7 Final package","text":"save, restart load packages can now see schemas loaded running sc::tm_get_schema_names(). can now see schemas made included.can alsp see tasks loaded running sc::tm_get_task_names(). tasks included skeleton.","code":"\nsc::tm_get_schema_names()\n## [1] \"config_last_updated\"                                           \"config_structure_time\"                                        \n## [3] \"rundate\"                                                       \"config_datetime\"                                              \n## [5] \"anon_example_weather_rawdata\"                                  \"anon_example_weather_data\"                                    \n## [7] \"anon_example_income\"                                           \"anon_example_house_prices\"                                    \n## [9] \"anon_example_house_prices_outliers_after_adjusting_for_income\"\nsc::tm_get_task_names()\n## [1] \"weather_download_and_import_rawdata\"                            \"weather_clean_data\"                                            \n## [3] \"weather_export_plots\"                                           \"household_incomes_and_house_prices_import_data\"                \n## [5] \"household_incomes_and_house_prices_fit_model_and_find_outliers\" \"household_incomes_and_house_prices_plot\""},{"path":"tutorial-1-introduction.html","id":"running","chapter":"4 Tutorial 1: Introduction","heading":"4.7.1 Running","text":"can now run tasks console want. Note use scskeleton::tm_run_task instead sc::tm_run_task. want ensure scexample::.onLoad called authenticates .Congratulations! now successfully finnished first tutorial Sykdomspulsen Core.","code":"\nscskeleton::tm_run_task(\"weather_download_and_import_rawdata\")\nscskeleton::tm_run_task(\"weather_clean_data\")\nscskeleton::tm_run_task(\"weather_export_weather_plots\")"},{"path":"tutorial-1-introduction.html","id":"what-now","chapter":"4 Tutorial 1: Introduction","heading":"4.8 What now?","text":"Tutorial 1, expect understand four fundamental parts developing task:SchemasTask definition (task_from_config)data_selector_fnaction_fnWe also expect can:Run task using tm_run_taskUse sc::tm_get_plans_argsets_as_dt identify index_plan index_analysis corresponds plan/analysis interested (e.g. Oslo)Run inside code data_selector_fn different index_plans interactive scriptRun inside code action_fn different index_plans index_analysiss interactive script","code":""}]
